{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOAIpcAZwc32KLcqY35LQ+0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andandandand/practical-computer-vision/blob/main/notebooks/Exploring_Object_Detection_with_FiftyOne_on_COCO_2017.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Object Detection Performance with FiftyOne\n",
        "\n",
        "In this notebook we examine the performance of a pretrained [RetinaNet](https://arxiv.org/abs/1708.02002) on the [COCO 2017 validation set](https://cocodataset.org/#home), through the open source [FiftyOne](https://github.com/voxel51/fiftyone) SDK and visualization app.\n",
        "\n",
        "It covers the following concepts:\n",
        "\n",
        "- Loading a dataset with ground truth labels [into FiftyOne](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/index.html)\n",
        "- [Adding model predictions](https://voxel51.com/docs/fiftyone/recipes/adding_detections.html) to your dataset\n",
        "- [Evaluating your model](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#detections) using FiftyOne's evaluation API\n",
        "- Viewing the best and worst performing samples in your dataset\n",
        "\n",
        "**So, what's the takeaway?**\n",
        "\n",
        "Aggregate measures of performance like [mean Average Precision](https://kili-technology.com/data-labeling/machine-learning/mean-average-precision-map-a-complete-guide) don't give us the full picture of your detection model. In practice, the limiting factor on your model's performance is often data quality issues that we need to **see** to address. FiftyOne is designed to make it easy to do just that.\n",
        "\n",
        "## Inspecting your datasets\n",
        "\n",
        "Running the workflow presented here on your ML projects will help you to understand the current failure modes (edge cases) of your model and how to fix them, including:\n",
        "\n",
        "- Identifying scenarios that require additional training samples in order to boost your model's performance\n",
        "- Deciding whether your ground truth annotations have errors/weaknesses that need to be corrected before any subsequent model training will be profitable\n",
        "\n",
        "\n",
        "This walkthrough demonstrates how to use FiftyOne to perform hands-on evaluation of your detection model."
      ],
      "metadata": {
        "id": "Lemoi2vjMw5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install FiftyOne"
      ],
      "metadata": {
        "id": "lmw0PeIsMruf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "bmi7POz6UpHq"
      },
      "outputs": [],
      "source": [
        "# Install the library, you will need to uncomment this on Colab\n",
        "#!pip install fiftyone==1.5.2 > /dev/null\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check installed versions\n",
        "import fiftyone as fo\n",
        "print(f\"FiftyOne version: {fo.__version__}\")\n",
        "\n",
        "import fiftyone.zoo as foz\n",
        "import fiftyone.brain as fob # Import common modules once at the top\n",
        "from fiftyone import ViewField as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofBUqpYvV8te",
        "outputId": "e155bc71-e5cd-46ee-91ac-b7851f9b451b"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FiftyOne version: 1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loading"
      ],
      "metadata": {
        "id": "F7fm78guiRlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",\n",
        "    dataset_name=\"evaluate-detections-tutorial\",\n",
        ")\n",
        "dataset.persistent = True\n",
        "dataset_clone = dataset.clone()\n",
        "dataset_clone.persistent = True\n",
        "\n",
        "print(\"Dataset loaded.\")\n",
        "\n",
        "# Let's inspect the first sample of the dataset.\n",
        "# This will show its filepath, tags, metadata, and any existing fields like 'ground_truth'.\n",
        "print(dataset_clone.first())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0nwZLduUx8t",
        "outputId": "7ccba804-08f1-4e5c-e52b-ac9d538d54da"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing download of split 'validation' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Existing download of split 'validation' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing dataset 'evaluate-detections-tutorial'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading existing dataset 'evaluate-detections-tutorial'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded.\n",
            "<Sample: {\n",
            "    'id': '6824a5ae117eced94bbe9951',\n",
            "    'media_type': 'image',\n",
            "    'filepath': '/root/fiftyone/coco-2017/validation/data/000000000139.jpg',\n",
            "    'tags': ['validation'],\n",
            "    'metadata': <ImageMetadata: {\n",
            "        'size_bytes': None,\n",
            "        'mime_type': None,\n",
            "        'width': 640,\n",
            "        'height': 426,\n",
            "        'num_channels': None,\n",
            "    }>,\n",
            "    'created_at': datetime.datetime(2025, 5, 14, 15, 3, 18, 171000),\n",
            "    'last_modified_at': datetime.datetime(2025, 5, 14, 15, 3, 18, 171000),\n",
            "    'ground_truth': <Detections: {\n",
            "        'detections': [\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe993d',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'potted plant',\n",
            "                'bounding_box': [\n",
            "                    0.37028125,\n",
            "                    0.3345305164319249,\n",
            "                    0.038593749999999996,\n",
            "                    0.16314553990610328,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe993e',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'tv',\n",
            "                'bounding_box': [\n",
            "                    0.010984375000000001,\n",
            "                    0.39380281690140845,\n",
            "                    0.23331249999999998,\n",
            "                    0.22269953051643193,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'electronic',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe993f',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'tv',\n",
            "                'bounding_box': [\n",
            "                    0.8706406250000001,\n",
            "                    0.491056338028169,\n",
            "                    0.127109375,\n",
            "                    0.18481220657276995,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'electronic',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe9940',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'chair',\n",
            "                'bounding_box': [\n",
            "                    0.56090625,\n",
            "                    0.5118544600938968,\n",
            "                    0.0875,\n",
            "                    0.24138497652582158,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe9941',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'chair',\n",
            "                'bounding_box': [\n",
            "                    0.454203125,\n",
            "                    0.5117370892018779,\n",
            "                    0.096609375,\n",
            "                    0.2311737089201878,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe9942',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'chair',\n",
            "                'bounding_box': [\n",
            "                    0.645625,\n",
            "                    0.5234976525821596,\n",
            "                    0.047140625000000005,\n",
            "                    0.19098591549295774,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe9943',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'chair',\n",
            "                'bounding_box': [\n",
            "                    0.4959375,\n",
            "                    0.5146478873239437,\n",
            "                    0.03371875,\n",
            "                    0.02720657276995305,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe9944',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'person',\n",
            "                'bounding_box': [\n",
            "                    0.645,\n",
            "                    0.3699765258215963,\n",
            "                    0.082890625,\n",
            "                    0.3239671361502347,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'person',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe9945',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'person',\n",
            "                'bounding_box': [\n",
            "                    0.600671875,\n",
            "                    0.40424882629107983,\n",
            "                    0.023625,\n",
            "                    0.08389671361502347,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'person',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe9946',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'microwave',\n",
            "                'bounding_box': [\n",
            "                    0.80034375,\n",
            "                    0.482981220657277,\n",
            "                    0.02303125,\n",
            "                    0.037488262910798126,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'appliance',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe9947',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'refrigerator',\n",
            "                'bounding_box': [\n",
            "                    0.77046875,\n",
            "                    0.40924882629107984,\n",
            "                    0.031703125,\n",
            "                    0.2542488262910798,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'appliance',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe9948',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'book',\n",
            "                'bounding_box': [\n",
            "                    0.944953125,\n",
            "                    0.7180516431924883,\n",
            "                    0.02240625,\n",
            "                    0.10730046948356808,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe9949',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'book',\n",
            "                'bounding_box': [\n",
            "                    0.9581875,\n",
            "                    0.7235680751173709,\n",
            "                    0.020125,\n",
            "                    0.10901408450704225,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe994a',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'clock',\n",
            "                'bounding_box': [\n",
            "                    0.699640625,\n",
            "                    0.2843192488262911,\n",
            "                    0.021828125,\n",
            "                    0.05136150234741784,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe994b',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'vase',\n",
            "                'bounding_box': [\n",
            "                    0.8579062499999999,\n",
            "                    0.7263615023474178,\n",
            "                    0.0573125,\n",
            "                    0.2104929577464789,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe994c',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'vase',\n",
            "                'bounding_box': [\n",
            "                    0.5480625,\n",
            "                    0.4902347417840376,\n",
            "                    0.017765625,\n",
            "                    0.05293427230046949,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe994d',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'chair',\n",
            "                'bounding_box': [\n",
            "                    0.644140625,\n",
            "                    0.514131455399061,\n",
            "                    0.015046875000000001,\n",
            "                    0.029389671361502348,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe994e',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'vase',\n",
            "                'bounding_box': [\n",
            "                    0.37693750000000004,\n",
            "                    0.4577230046948357,\n",
            "                    0.022218750000000002,\n",
            "                    0.04138497652582159,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe994f',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'vase',\n",
            "                'bounding_box': [\n",
            "                    0.526234375,\n",
            "                    0.46830985915492956,\n",
            "                    0.015203125000000001,\n",
            "                    0.039272300469483566,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6824a5ae117eced94bbe9950',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'dining table',\n",
            "                'bounding_box': [\n",
            "                    0.5018906249999999,\n",
            "                    0.5427699530516432,\n",
            "                    0.19618750000000001,\n",
            "                    0.20875586854460096,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "        ],\n",
            "    }>,\n",
            "}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choose a random subset of samples to add predictions to"
      ],
      "metadata": {
        "id": "kK9knjkzDXIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_view = dataset_clone.take(100, seed=51)"
      ],
      "metadata": {
        "id": "Mm8psUP-DbTV"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = foz.load_zoo_model(\"retinanet-resnet50-fpn-coco-torch\")\n"
      ],
      "metadata": {
        "id": "Bawj4ThsEVfA"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_view.apply_model(model, label_field=\"predictions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qJv1jJSEXLz",
        "outputId": "18713da3-0450-416c-93e6-e1a302c03a03"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 100/100 [5.6s elapsed, 0s remaining, 18.3 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 100/100 [5.6s elapsed, 0s remaining, 18.3 samples/s]      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session = fo.launch_app(predictions_view, auto=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6F0KE4nEhgj",
        "outputId": "165c32c8-9faf-42c4-8f70-371362a29b50"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session launched. Run `session.show()` to open the App in a cell output.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.core.session.session:Session launched. Run `session.show()` to open the App in a cell output.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shows the predictions on the view only\n",
        "session.view = predictions_view\n",
        "print(session.url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "zpl_FN2iEebK",
        "outputId": "fc8ed702-0442-4f3c-c7e0-167ee3226c6d"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5151-gpu-l4-s-2o06qwtjrrtks-a.us-west4-0.prod.colab.dev?polling=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resets the session; the entire dataset will now be shown\n",
        "session.view = None\n",
        "print(session.url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "46X7Vi6UEzfo",
        "outputId": "9eef60b3-14a4-44bb-9151-9fe369192f33"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5151-gpu-l4-s-2o06qwtjrrtks-a.us-west4-0.prod.colab.dev?polling=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Going back to showing the view\n",
        "session.view = predictions_view\n",
        "print(session.url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "fjkKPtB1F3N8",
        "outputId": "5ad9a733-69af-4583-a7ad-c394cc452458"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5151-gpu-l4-s-2o06qwtjrrtks-a.us-west4-0.prod.colab.dev?polling=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now try inspecting the predictions with confidence > 0.75"
      ],
      "metadata": {
        "id": "nO6tua7HGKtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/predictions.png?raw=true)"
      ],
      "metadata": {
        "id": "8EtRLTYVG-77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confidence threshold through the SDK"
      ],
      "metadata": {
        "id": "bd8BVqxkHKad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only contains detections with confidence >= 0.75\n",
        "high_conf_view = predictions_view.filter_labels(\"predictions\",\n",
        "                                                F(\"confidence\") > 0.75,\n",
        "                                                only_matches=False)"
      ],
      "metadata": {
        "id": "T0r2X42KHRcB"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the `only_matches=False` argument. When filtering labels, any samples that no longer contain labels would normally be removed from the view. However, this is not desired when performing evaluations since it can skew your results between views. We set `only_matches=False` so that all samples will be retained, even if some no longer contain labels."
      ],
      "metadata": {
        "id": "XfphZjEOHdh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some information about the view\n",
        "print(high_conf_view)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goOclyruHhQT",
        "outputId": "54145199-cebe-46d5-8ead-70fde18f4224"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:     2025.05.14.15.03.18.155643\n",
            "Media type:  image\n",
            "Num samples: 100\n",
            "Sample fields:\n",
            "    id:               fiftyone.core.fields.ObjectIdField\n",
            "    filepath:         fiftyone.core.fields.StringField\n",
            "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    created_at:       fiftyone.core.fields.DateTimeField\n",
            "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
            "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    predictions:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "View stages:\n",
            "    1. Take(size=100, seed=51)\n",
            "    2. FilterLabels(field='predictions', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a prediction from the view to verify that its confidence is > 0.75\n",
        "sample = high_conf_view.first()\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OegCfpaAHmSj",
        "outputId": "afbe79e9-f165-4cb8-b8f1-de3b88922e56"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SampleView: {\n",
              "    'id': '6824a5b5117eced94bbec3a2',\n",
              "    'media_type': 'image',\n",
              "    'filepath': '/root/fiftyone/coco-2017/validation/data/000000151051.jpg',\n",
              "    'tags': ['validation'],\n",
              "    'metadata': <ImageMetadata: {\n",
              "        'size_bytes': None,\n",
              "        'mime_type': None,\n",
              "        'width': 640,\n",
              "        'height': 478,\n",
              "        'num_channels': None,\n",
              "    }>,\n",
              "    'created_at': datetime.datetime(2025, 5, 14, 15, 3, 18, 171000),\n",
              "    'last_modified_at': datetime.datetime(2025, 5, 14, 15, 3, 18, 655000),\n",
              "    'ground_truth': <Detections: {\n",
              "        'detections': [\n",
              "            <Detection: {\n",
              "                'id': '6824a5b5117eced94bbec2e2',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [\n",
              "                    0.20631249999999998,\n",
              "                    0.42043933054393307,\n",
              "                    0.2070625,\n",
              "                    0.2446234309623431,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6824a5b5117eced94bbec2e3',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'skis',\n",
              "                'bounding_box': [\n",
              "                    0.207671875,\n",
              "                    0.694163179916318,\n",
              "                    0.36234375,\n",
              "                    0.17920502092050208,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'sports',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "        ],\n",
              "    }>,\n",
              "    'predictions': <Detections: {\n",
              "        'detections': [\n",
              "            <Detection: {\n",
              "                'id': '6824b0b6117eced94bbf5ce5',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [\n",
              "                    0.21051760017871857,\n",
              "                    0.4170771539211273,\n",
              "                    0.20937219262123108,\n",
              "                    0.27810138463974,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': 0.9692026376724243,\n",
              "                'index': None,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6824b0b6117eced94bbf5ce6',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'snowboard',\n",
              "                'bounding_box': [\n",
              "                    0.20866338908672333,\n",
              "                    0.6957019567489624,\n",
              "                    0.0928565263748169,\n",
              "                    0.06648726761341095,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': 0.7724683284759521,\n",
              "                'index': None,\n",
              "            }>,\n",
              "        ],\n",
              "    }>,\n",
              "}>"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load high confidence view in the App\n",
        "session.view = high_conf_view\n",
        "print(session.url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "NotryRGDKmNW",
        "outputId": "7606d8f5-f07e-450b-aee6-4847737cdd5e"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5151-gpu-l4-s-2o06qwtjrrtks-a.us-west4-0.prod.colab.dev?polling=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try inspecting patches on the view\n",
        "\n",
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/inspecting_patches.png?raw=true)"
      ],
      "metadata": {
        "id": "zXO_9a6oLZTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate predictions\n"
      ],
      "metadata": {
        "id": "fiCTnawjKnTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the predictions in the `faster_rcnn` field of our `high_conf_view`\n",
        "# with respect to the objects in the `ground_truth` field\n",
        "results = high_conf_view.evaluate_detections(\n",
        "    \"predictions\",\n",
        "    gt_field=\"ground_truth\",\n",
        "    eval_key=\"eval\",\n",
        "    compute_mAP=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NNmE83pL4Ga",
        "outputId": "57b317c4-4908-42a3-a628-ec03a39f8ce8"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.detection:Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 100/100 [1.4s elapsed, 0s remaining, 58.6 samples/s]          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 100/100 [1.4s elapsed, 0s remaining, 58.6 samples/s]          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.coco:Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 100/100 [1.1s elapsed, 0s remaining, 84.4 samples/s]          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 100/100 [1.1s elapsed, 0s remaining, 84.4 samples/s]          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the 10 most common classes in the dataset\n",
        "counts = dataset_clone.count_values(\"ground_truth.detections.label\")\n",
        "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
        "\n",
        "# Print a classification report for the top-10 classes\n",
        "results.print_report(classes=classes_top10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DcWl-EDL5Jd",
        "outputId": "e1d52f86-5757-41fb-84cc-5909afca186e"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "       person       0.99      0.40      0.57       217\n",
            "          car       1.00      0.48      0.65        25\n",
            "        chair       1.00      0.15      0.26        40\n",
            "         book       0.00      0.00      0.00        52\n",
            "       bottle       0.50      0.04      0.07        27\n",
            "          cup       1.00      0.07      0.13        29\n",
            " dining table       0.00      0.00      0.00        21\n",
            "traffic light       0.00      0.00      0.00         1\n",
            "         bowl       0.00      0.00      0.00        17\n",
            "      handbag       0.00      0.00      0.00        14\n",
            "\n",
            "    micro avg       0.98      0.24      0.39       443\n",
            "    macro avg       0.45      0.11      0.17       443\n",
            " weighted avg       0.73      0.24      0.35       443\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results.mAP())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajfYElVXMBDP",
        "outputId": "ed1a8554-bd98-4837-d933-59a519142316"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2794843881248003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install ipywidgets if needed for the interactive plot below\n",
        "#!pip install 'ipywidgets>=8,<9'"
      ],
      "metadata": {
        "id": "UGhjHMVtML-f"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot = results.plot_pr_curves(classes=[\"person\", \"car\"])\n",
        "plot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "dP4JPVPDL-7n",
        "outputId": "39c45449-1f70-4666-f95a-8426eb2dd309"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b45bafc3-fce7-472c-8a72-9a91071d26a6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b45bafc3-fce7-472c-8a72-9a91071d26a6\")) {                    Plotly.newPlot(                        \"b45bafc3-fce7-472c-8a72-9a91071d26a6\",                        [{\"customdata\":[0.9431668519973755,0.9431668519973755,0.9431668519973755,0.9431668519973755,0.9431668519973755,0.9318227350711823,0.9318227350711823,0.9318227350711823,0.9318227350711823,0.9215119779109955,0.9215119779109955,0.9215119779109955,0.9215119779109955,0.9088511526584625,0.9088511526584625,0.9088511526584625,0.9088511526584625,0.8835643827915192,0.8835643827915192,0.8835643827915192,0.8835643827915192,0.8012424588203431,0.8012424588203431,0.8012424588203431,0.8012424588203431,0.7940021574497222,0.7940021574497222,0.7940021574497222,0.7940021574497222,0.7572171509265899,0.7572171509265899,0.7572171509265899,0.7572171509265899,0.7019316494464874,0.7019316494464874,0.7019316494464874,0.7019316494464874,0.686868566274643,0.686868566274643,0.686868566274643,0.686868566274643,0.5295764982700348,0.5295764982700348,0.5295764982700348,0.5295764982700348,0.5294364750385284,0.5294364750385284,0.5294364750385284,0.5294364750385284,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"hovertemplate\":\"\\u003cb\\u003eclass: %{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003erecall: %{x:.3f}\\u003cbr\\u003eprecision: %{y:.3f}\\u003cbr\\u003ethreshold: %{customdata:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#3366CC\"},\"mode\":\"lines\",\"name\":\"car (AP = 0.432)\",\"text\":[\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\"],\"x\":[0.0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3,0.31,0.32,0.33,0.34,0.35000000000000003,0.36,0.37,0.38,0.39,0.4,0.41000000000000003,0.42,0.43,0.44,0.45,0.46,0.47000000000000003,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.5700000000000001,0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.6900000000000001,0.7000000000000001,0.71,0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.8200000000000001,0.8300000000000001,0.84,0.85,0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.9400000000000001,0.9500000000000001,0.96,0.97,0.98,0.99,1.0],\"y\":[1.0,1.0,1.0,1.0,1.0,0.9666666666666666,0.9666666666666666,0.9666666666666666,0.9666666666666666,0.9666666666666666,0.9666666666666666,0.9666666666666666,0.9666666666666666,0.9666666666666666,0.9666666666666666,0.9666666666666666,0.9666666666666666,0.9416666666666667,0.9416666666666667,0.9416666666666667,0.9416666666666667,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.8800000000000001,0.8800000000000001,0.8800000000000001,0.8800000000000001,0.8800000000000001,0.8800000000000001,0.8800000000000001,0.8800000000000001,0.8666666666666666,0.8666666666666666,0.8666666666666666,0.8666666666666666,0.7,0.7,0.7,0.7,0.7,0.7,0.7,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"customdata\":[0.9898508787155151,0.9842216610908509,0.9805236995220185,0.9772367060184479,0.9700745701789856,0.9677409768104553,0.9620091795921326,0.9577589333057404,0.951621288061142,0.9409676730632782,0.85849050283432,0.8526163220405578,0.8485387682914733,0.8419727385044098,0.8325929820537568,0.8261240899562836,0.8082788467407227,0.7988800287246705,0.7938272416591644,0.7895117104053497,0.705386483669281,0.7013158440589905,0.6927871406078339,0.6890370428562165,0.6766297340393066,0.6714541673660278,0.6673224449157715,0.6619752824306488,0.580651044845581,0.574806421995163,0.5719953119754791,0.5652874410152435,0.5633246719837188,0.5587562024593353,0.4793126404285431,0.4757166802883148,0.4695607960224152,0.464774614572525,0.3862073063850403,0.3042517125606537,0.22707712650299072,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"hovertemplate\":\"\\u003cb\\u003eclass: %{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003erecall: %{x:.3f}\\u003cbr\\u003eprecision: %{y:.3f}\\u003cbr\\u003ethreshold: %{customdata:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#DC3912\"},\"mode\":\"lines\",\"name\":\"person (AP = 0.311)\",\"text\":[\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\"],\"x\":[0.0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3,0.31,0.32,0.33,0.34,0.35000000000000003,0.36,0.37,0.38,0.39,0.4,0.41000000000000003,0.42,0.43,0.44,0.45,0.46,0.47000000000000003,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.5700000000000001,0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.6900000000000001,0.7000000000000001,0.71,0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.8200000000000001,0.8300000000000001,0.84,0.85,0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.9400000000000001,0.9500000000000001,0.96,0.97,0.98,0.99,1.0],\"y\":[0.9666666666666666,0.9625,0.951388888888889,0.9427350427350427,0.9336700336700338,0.9318518518518519,0.9268518518518519,0.9222222222222222,0.9150757575757575,0.8976353555120677,0.8702380952380953,0.8661257606490871,0.8631845841784991,0.8570889894419306,0.8519607843137255,0.8457767722473605,0.825631407584728,0.8201213394983886,0.8193521087291579,0.8193521087291579,0.7635458409228901,0.7628635797143132,0.7597226629061637,0.7587452711223203,0.7555125544718821,0.7550580090173368,0.7550580090173368,0.7548573297953547,0.6793573698669493,0.6750265648755128,0.6737749179716921,0.669168364351433,0.6665232880419565,0.6659310985413163,0.5803889298666175,0.5803889298666175,0.5803889298666175,0.5803889298666175,0.48744775339602925,0.39204545454545453,0.29545454545454547,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(51,51,51)\"},\"error_y\":{\"color\":\"rgb(51,51,51)\"},\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"baxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"colorscale\":{\"sequential\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"sequentialminus\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]]},\"colorway\":[\"#F8766D\",\"#A3A500\",\"#00BF7D\",\"#00B0F6\",\"#E76BF3\"],\"font\":{\"color\":\"rgb(51,51,51)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(237,237,237)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(237,237,237)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"xaxis\":{\"range\":[0,1],\"constrain\":\"domain\",\"title\":{\"text\":\"Recall\"}},\"yaxis\":{\"range\":[0,1],\"constrain\":\"domain\",\"scaleanchor\":\"x\",\"scaleratio\":1,\"title\":{\"text\":\"Precision\"}},\"title\":{},\"margin\":{\"r\":0,\"t\":30,\"l\":0,\"b\":0}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b45bafc3-fce7-472c-8a72-9a91071d26a6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample level analysis"
      ],
      "metadata": {
        "id": "8dpR7eosMW4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Our dataset's schema now contains `eval_*` fields from a confusion matrix\n",
        "print(dataset_clone)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A--63fNMaWT",
        "outputId": "726f302f-cca6-416c-ed6f-6ab4c4df3d83"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:        2025.05.14.15.03.18.155643\n",
            "Media type:  image\n",
            "Num samples: 5000\n",
            "Persistent:  True\n",
            "Tags:        []\n",
            "Sample fields:\n",
            "    id:               fiftyone.core.fields.ObjectIdField\n",
            "    filepath:         fiftyone.core.fields.StringField\n",
            "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    created_at:       fiftyone.core.fields.DateTimeField\n",
            "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
            "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    predictions:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    eval_tp:          fiftyone.core.fields.IntField\n",
            "    eval_fp:          fiftyone.core.fields.IntField\n",
            "    eval_fn:          fiftyone.core.fields.IntField\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The dataset keeps track of the evaluations that we have run\n",
        "print(dataset_clone.list_evaluations())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOdEugOHO9xs",
        "outputId": "60ba63b5-7831-4c3e-ad94-247bc05999c8"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['eval']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_clone.get_evaluation_info(\"eval\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCqkfalVPIZM",
        "outputId": "474f16f2-10a6-4ed7-edfb-5c1fef610a38"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"key\": \"eval\",\n",
            "    \"version\": \"1.5.2\",\n",
            "    \"timestamp\": \"2025-05-14T15:03:33.136000\",\n",
            "    \"config\": {\n",
            "        \"cls\": \"fiftyone.utils.eval.coco.COCOEvaluationConfig\",\n",
            "        \"type\": \"detection\",\n",
            "        \"method\": \"coco\",\n",
            "        \"pred_field\": \"predictions\",\n",
            "        \"gt_field\": \"ground_truth\",\n",
            "        \"iou\": 0.5,\n",
            "        \"classwise\": true,\n",
            "        \"custom_metrics\": null,\n",
            "        \"iscrowd\": \"iscrowd\",\n",
            "        \"use_masks\": false,\n",
            "        \"use_boxes\": false,\n",
            "        \"tolerance\": null,\n",
            "        \"compute_mAP\": true,\n",
            "        \"iou_threshs\": [\n",
            "            0.5,\n",
            "            0.55,\n",
            "            0.6,\n",
            "            0.65,\n",
            "            0.7,\n",
            "            0.75,\n",
            "            0.8,\n",
            "            0.85,\n",
            "            0.9,\n",
            "            0.95\n",
            "        ],\n",
            "        \"max_preds\": 100,\n",
            "        \"error_level\": 1\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the view on which we ran the `eval` evaluation\n",
        "eval_view = dataset_clone.load_evaluation_view(\"eval\")\n",
        "print(eval_view)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTR8QO2uPR31",
        "outputId": "e67fc1fa-0adb-4eed-d462-a6c46ab654f4"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:     2025.05.14.15.03.18.155643\n",
            "Media type:  image\n",
            "Num samples: 100\n",
            "Sample fields:\n",
            "    id:               fiftyone.core.fields.ObjectIdField\n",
            "    filepath:         fiftyone.core.fields.StringField\n",
            "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    created_at:       fiftyone.core.fields.DateTimeField\n",
            "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
            "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    predictions:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    eval_tp:          fiftyone.core.fields.IntField\n",
            "    eval_fp:          fiftyone.core.fields.IntField\n",
            "    eval_fn:          fiftyone.core.fields.IntField\n",
            "View stages:\n",
            "    1. Take(size=100, seed=51)\n",
            "    2. FilterLabels(field='predictions', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Our detections have helpful evaluation data on them\n",
        "sample = high_conf_view.first()\n",
        "print(sample.predictions.detections[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8EzkeZrMdYM",
        "outputId": "19d22bbd-efd2-43a7-cfb4-f23d16763e7d"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Detection: {\n",
            "    'id': '6824b0b6117eced94bbf5ce5',\n",
            "    'attributes': {},\n",
            "    'tags': [],\n",
            "    'label': 'person',\n",
            "    'bounding_box': [\n",
            "        0.21051760017871857,\n",
            "        0.4170771539211273,\n",
            "        0.20937219262123108,\n",
            "        0.27810138463974,\n",
            "    ],\n",
            "    'mask': None,\n",
            "    'mask_path': None,\n",
            "    'confidence': 0.9692026376724243,\n",
            "    'index': None,\n",
            "    'eval_iou': 0.8374545505080747,\n",
            "    'eval_id': '6824a5b5117eced94bbec2e2',\n",
            "    'eval': 'tp',\n",
            "}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the `iscrowd` attribute on a ground truth object\n",
        "sample = dataset_clone.first()\n",
        "print(sample.ground_truth.detections[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkoSH1D8MbAF",
        "outputId": "35317773-b596-4954-ddad-dc73bbc4074b"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Detection: {\n",
            "    'id': '6824a5ae117eced94bbe993d',\n",
            "    'attributes': {},\n",
            "    'tags': [],\n",
            "    'label': 'potted plant',\n",
            "    'bounding_box': [\n",
            "        0.37028125,\n",
            "        0.3345305164319249,\n",
            "        0.038593749999999996,\n",
            "        0.16314553990610328,\n",
            "    ],\n",
            "    'mask': None,\n",
            "    'mask_path': None,\n",
            "    'confidence': None,\n",
            "    'index': None,\n",
            "    'supercategory': 'furniture',\n",
            "    'iscrowd': 0,\n",
            "}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation patches"
      ],
      "metadata": {
        "id": "bBZmKE4BN7JQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, now that we have a sense for the aggregate performance of our model, let's dive into sample-level analysis by creating an [evaluation view](https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-evaluation-patches).\n",
        "\n",
        "Any evaluation that you stored on your dataset can be used to generate an [evaluation view](https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-evaluation-patches) that is a patches view creating a sample for every true positive, false positive, and false negative in your dataset.\n",
        "Through this view, you can quickly filter and sort evaluated detections by their type (TP/FP/FN), evaluated IoU, and if they are matched to a crowd object.\n",
        "\n",
        "These evaluation views can be created through Python or directly in the App as shown below."
      ],
      "metadata": {
        "id": "hnQqEcRXPm6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_patches = dataset_clone.to_evaluation_patches(\"eval\")\n",
        "print(eval_patches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fx0EvjVPcDX",
        "outputId": "15d94b55-c444-483c-c2af-b6e866cad53d"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:     2025.05.14.15.03.18.155643\n",
            "Media type:  image\n",
            "Num patches: 37593\n",
            "Patch fields:\n",
            "    id:               fiftyone.core.fields.ObjectIdField\n",
            "    sample_id:        fiftyone.core.fields.ObjectIdField\n",
            "    filepath:         fiftyone.core.fields.StringField\n",
            "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    created_at:       fiftyone.core.fields.DateTimeField\n",
            "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
            "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    predictions:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    crowd:            fiftyone.core.fields.BooleanField\n",
            "    type:             fiftyone.core.fields.StringField\n",
            "    iou:              fiftyone.core.fields.FloatField\n",
            "View stages:\n",
            "    1. ToEvaluationPatches(eval_key='eval', config=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's use this evaluation to find false positives with confidence above > .85\n",
        "session_view = high_conf_view\n",
        "print(session.url )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "MFFVnezFPrEz",
        "outputId": "90eef9a4-b81d-40d9-cc63-a1191f0c668b"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5151-gpu-l4-s-2o06qwtjrrtks-a.us-west4-0.prod.colab.dev?polling=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/false_positive.png?raw=true)"
      ],
      "metadata": {
        "id": "gE9-FIvNQ5Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View with best performing cases"
      ],
      "metadata": {
        "id": "sCLke7VaRtAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show samples with most true positives\n",
        "session.view = high_conf_view.sort_by(\"eval_tp\", reverse=True)\n",
        "print(session.url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-PSPhsHnR88M",
        "outputId": "78606404-7791-48fd-ee60-7db67610aa2c"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5151-gpu-l4-s-2o06qwtjrrtks-a.us-west4-0.prod.colab.dev?polling=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View with the worst performing cases by false positives"
      ],
      "metadata": {
        "id": "ihCEA2KaSHAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show samples with most false positives\n",
        "session.view = high_conf_view.sort_by(\"eval_fp\", reverse=True)\n",
        "print(session.url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "z_Xp3tstR-NL",
        "outputId": "8d219e9e-1936-4b60-b753-5064c859e828"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5151-gpu-l4-s-2o06qwtjrrtks-a.us-west4-0.prod.colab.dev?polling=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View with the best performing cases by false negatives"
      ],
      "metadata": {
        "id": "EK8mbOBdSQ9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show samples with most false negatives\n",
        "session.view = high_conf_view.sort_by(\"eval_fn\", reverse=True)\n",
        "print(session.url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "h9slf4XWSX6F",
        "outputId": "6220cb49-4737-4c9e-94fe-b35f728746ab"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5151-gpu-l4-s-2o06qwtjrrtks-a.us-west4-0.prod.colab.dev?polling=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering by bounding box area"
      ],
      "metadata": {
        "id": "qCMZJcBDSagN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute metadata so we can reference image height/width in our view\n",
        "dataset.compute_metadata()"
      ],
      "metadata": {
        "id": "TTlArhXuSkPm"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Create an expression that will match objects whose bounding boxes have\n",
        "# area less than 32^2 pixels\n",
        "#\n",
        "# Bounding box format is [top-left-x, top-left-y, width, height]\n",
        "# with relative coordinates in [0, 1], so we multiply by image\n",
        "# dimensions to get pixel area\n",
        "#\n",
        "bbox_area = (\n",
        "    F(\"$metadata.width\") * F(\"bounding_box\")[2] *\n",
        "    F(\"$metadata.height\") * F(\"bounding_box\")[3]\n",
        ")\n",
        "small_boxes = bbox_area < 32 ** 2\n",
        "\n",
        "# Create a view that contains only small (and high confidence) predictions\n",
        "small_boxes_view = high_conf_view.filter_labels(\"predictions\", small_boxes)\n",
        "\n",
        "session.view = small_boxes_view\n",
        "print(session.url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "yCEC4s_nSme3",
        "outputId": "d6f29223-0026-4c69-ec08-066f34fbd750"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5151-gpu-l4-s-2o06qwtjrrtks-a.us-west4-0.prod.colab.dev?polling=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a view that contains only small GT and predicted boxes\n",
        "small_boxes_eval_view = (\n",
        "    high_conf_view\n",
        "    .filter_labels(\"ground_truth\", small_boxes, only_matches=False)\n",
        "    .filter_labels(\"predictions\", small_boxes, only_matches=False)\n",
        ")\n",
        "\n",
        "# Run evaluation\n",
        "small_boxes_results = small_boxes_eval_view.evaluate_detections(\n",
        "    \"predictions\",\n",
        "    gt_field=\"ground_truth\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZgTtZObSpKj",
        "outputId": "d67e949e-b0cc-4cc8-ea1b-907ab8f4dec4"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.detection:Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 100/100 [238.5ms elapsed, 0s remaining, 419.3 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 100/100 [238.5ms elapsed, 0s remaining, 419.3 samples/s]      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the 10 most common small object classes\n",
        "small_counts = small_boxes_eval_view.count_values(\"ground_truth.detections.label\")\n",
        "classes_top10_small = sorted(small_counts, key=counts.get, reverse=True)[:10]\n",
        "\n",
        "# Print a classification report for the top-10 small object classes\n",
        "small_boxes_results.print_report(classes=classes_top10_small)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZURNr4GS5pQ",
        "outputId": "9c558a4a-d23d-4f52-ebbe-711ed1dff2da"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "       person       1.00      0.04      0.08        47\n",
            "          car       0.00      0.00      0.00         6\n",
            "        chair       0.00      0.00      0.00         7\n",
            "         book       0.00      0.00      0.00        32\n",
            "       bottle       0.00      0.00      0.00        13\n",
            "          cup       0.00      0.00      0.00        16\n",
            " dining table       0.00      0.00      0.00         1\n",
            "traffic light       0.00      0.00      0.00         1\n",
            "         bowl       0.00      0.00      0.00         7\n",
            "      handbag       0.00      0.00      0.00         3\n",
            "\n",
            "    micro avg       1.00      0.02      0.03       133\n",
            "    macro avg       0.10      0.00      0.01       133\n",
            " weighted avg       0.35      0.02      0.03       133\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspecting the crowd views"
      ],
      "metadata": {
        "id": "PUodNpp3TLlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the `iscrowd` attribute on a ground truth object\n",
        "sample = dataset_clone.first()\n",
        "print(sample.ground_truth.detections[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix1viEAcTAUd",
        "outputId": "12af113e-ea32-457f-eb89-60e31632ce1f"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Detection: {\n",
            "    'id': '6824a5ae117eced94bbe993d',\n",
            "    'attributes': {},\n",
            "    'tags': [],\n",
            "    'label': 'potted plant',\n",
            "    'bounding_box': [\n",
            "        0.37028125,\n",
            "        0.3345305164319249,\n",
            "        0.038593749999999996,\n",
            "        0.16314553990610328,\n",
            "    ],\n",
            "    'mask': None,\n",
            "    'mask_path': None,\n",
            "    'confidence': None,\n",
            "    'index': None,\n",
            "    'supercategory': 'furniture',\n",
            "    'iscrowd': 0,\n",
            "}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a view that contains only samples for which at least one detection has\n",
        "# its iscrowd attribute set to 1\n",
        "crowded_images_view = high_conf_view.match(\n",
        "    F(\"ground_truth.detections\").filter(F(\"iscrowd\") == 1).length() > 0\n",
        ")\n",
        "\n",
        "session.view = crowded_images_view\n",
        "print(session.url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "JeX15hDlTEGD",
        "outputId": "939b206e-1736-4761-fbed-06a18ae85a89"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5151-gpu-l4-s-2o06qwtjrrtks-a.us-west4-0.prod.colab.dev?polling=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the crowd by the number of false positives\n",
        "session.view = crowded_images_view.sort_by(\"eval_fp\", reverse=True)\n",
        "print(session.url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1lGHbQwjTP5f",
        "outputId": "84165826-49d1-45fc-dd48-a4d1f870f912"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://5151-gpu-l4-s-2o06qwtjrrtks-a.us-west4-0.prod.colab.dev?polling=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the model to improve the dataset (active learning)"
      ],
      "metadata": {
        "id": "DdR3T7rgUy2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tag all highly confident false positives as \"possibly-missing\"\n",
        "(\n",
        "    high_conf_view\n",
        "        .filter_labels(\"predictions\", F(\"eval\") == \"fp\")\n",
        "        .select_fields(\"predictions\")\n",
        "        .tag_labels(\"possibly-missing\")\n",
        ")"
      ],
      "metadata": {
        "id": "oYjvUA63Uh7o"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These tagged labels could then be sent off to our annotation provider of choice for review and addition to the ground truth labels. FiftyOne currently offers integrations for [Scale AI](https://voxel51.com/docs/fiftyone/api/fiftyone.utils.scale.html), [Labelbox](https://voxel51.com/docs/fiftyone/api/fiftyone.utils.labelbox.html), and [CVAT](https://voxel51.com/docs/fiftyone/api/fiftyone.types.dataset_types.html?highlight=cvat#fiftyone.types.dataset_types.CVATImageDataset).\n"
      ],
      "metadata": {
        "id": "PKcDI-_DVP0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export all labels with the `possibly-missing` tag in CVAT format\n",
        "(\n",
        "    dataset\n",
        "        .select_labels(tags=[\"possibly-missing\"])\n",
        "        .export(\"./possibly_missing_labels\", fo.types.CVATImageDataset)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TddG37ygTwmB",
        "outputId": "8330b800-c927-47be-8279-f2e4b633f918"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████████| 0/0 [32.9ms elapsed, ? remaining, ? samples/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████████| 0/0 [32.9ms elapsed, ? remaining, ? samples/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, we covered loading a dataset into FiftyOne and analyzing the performance of an out-of-the-box object detection model on the dataset.\n",
        "\n",
        "**So, what's the takeaway?**\n",
        "\n",
        "Aggregate evaluation results for an object detector are important, but they alone don't tell the whole story of a model's performance. It's critical to study the failure modes of your model so you can take the right actions to improve them.\n",
        "\n",
        "In this tutorial, we covered two types of analysis:\n",
        "\n",
        "- Analyzing the performance of your detector across different strata, like high confidence, small objects in crowded scenes\n",
        "- Inspecting the hardest samples in your dataset to diagnose the underlying issue, whether it be your detector or the ground truth annotations"
      ],
      "metadata": {
        "id": "Uz4z1poBVLzx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About this tutorial\n",
        "\n",
        "This tutorial is based on [FiftyOne's documentation](https://docs.voxel51.com/tutorials/evaluate_detections.html). You will notice a couple of minor changes.\n",
        "\n",
        "* Views for the app launch on their own window, this makes it easier for us to inspect the output of our views on the app.\n",
        "* We create a clone of the COCO dataset at the start of the notebook so that we can go back to its original state if we want\n",
        "* I replaced Faster R-CNN for RetinaNet. As an exercise I encourage to try it with [Faster R-CNN from our model zoo](https://docs.voxel51.com/model_zoo/models.html#faster-rcnn-resnet50-fpn-coco-torch) or through our [integration with Ultralytics's YOLO](https://docs.voxel51.com/integrations/ultralytics.html).\n",
        "\n"
      ],
      "metadata": {
        "id": "QRQvXyp-VZxa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K3Z1BeHDZAG-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}