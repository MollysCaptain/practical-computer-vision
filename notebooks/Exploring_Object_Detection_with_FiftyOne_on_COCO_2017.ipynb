{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "2fb42",
        "id": "Lemoi2vjMw5q"
      },
      "source": [
        "# Exploring Object Detection Performance with FiftyOne\n",
        "\n",
        "In this notebook we compare the performance of a pretrained [RetinaNet](https://arxiv.org/abs/1708.02002) and a pretrained [Faster-RCNN model](https://arxiv.org/abs/1506.01497) on the [COCO 2017 validation set](https://cocodataset.org/#home), through the open source [FiftyOne](https://github.com/voxel51/fiftyone) SDK and visualization app.\n",
        "\n",
        "It covers the following concepts:\n",
        "\n",
        "- Loading a dataset with ground truth labels [into FiftyOne](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/index.html)\n",
        "- [Adding model predictions](https://voxel51.com/docs/fiftyone/recipes/adding_detections.html) to your dataset\n",
        "- [Evaluating your model](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#detections) using FiftyOne's evaluation API\n",
        "- Viewing the best and worst performing samples in your dataset\n",
        "\n",
        "## Brief technical background\n",
        "\n",
        "There is a big variety of object detection algorithms out there. Among those based on the filtering of region proposals (aka anchor boxes), there are two main families:\n",
        "\n",
        "* Single shot detectors (SSDs) like RetinaNet and YOLO\n",
        "* Two stage detectors like Faster R-CNN\n",
        "\n",
        "Two stage detectors filter out candidate region proposals before producing output detections. Single shot detectors evaluate all region proposals at once.\n",
        "SSDs have the reputation of being faster, while two stage detectors seem to work better on small objects. We will put this last statement to the test in this example.\n",
        "\n",
        "**What's the takeaway?**\n",
        "\n",
        "Aggregate measures of performance like [mean Average Precision](https://kili-technology.com/data-labeling/machine-learning/mean-average-precision-map-a-complete-guide) don't give us the full picture of your detection model. In practice, the limiting factor on your model's performance is often data quality issues that we need to **see** to address. FiftyOne is designed to make it easy to do just that.\n",
        "\n",
        "## Inspecting your datasets\n",
        "\n",
        "Running the workflow presented here on your ML projects will help you to understand the current failure modes (edge cases) of your model and how to fix them, including:\n",
        "\n",
        "- Identifying scenarios that require additional training samples in order to boost your model's performance\n",
        "- Deciding whether your ground truth annotations have errors/weaknesses that need to be corrected before any subsequent model training will be profitable\n",
        "\n",
        "\n",
        "This walkthrough demonstrates how to use FiftyOne to perform hands-on evaluation of your detection model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "a06d0",
        "id": "lmw0PeIsMruf"
      },
      "source": [
        "## Install FiftyOne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellUniqueIdByVincent": "00165",
        "id": "bmi7POz6UpHq"
      },
      "outputs": [],
      "source": [
        "# Install the library, you will need to uncomment this on Colab\n",
        "#!pip install fiftyone==1.5.2 > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellUniqueIdByVincent": "057e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofBUqpYvV8te",
        "outputId": "106d51eb-f12c-4b8b-dcd2-ea75f0a938f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FiftyOne version: 1.5.2\n"
          ]
        }
      ],
      "source": [
        "#Check installed versions\n",
        "import fiftyone as fo\n",
        "print(f\"FiftyOne version: {fo.__version__}\")\n",
        "\n",
        "import fiftyone.zoo as foz\n",
        "import fiftyone.brain as fob\n",
        "from fiftyone import ViewField as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "14dd1",
        "id": "F7fm78guiRlU"
      },
      "source": [
        "## Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "1bb1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0nwZLduUx8t",
        "outputId": "4d461cc8-321d-4f8c-9f2e-51fe1a5d9350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading split 'validation' to '/Users/antonio/fiftyone/coco-2017/validation' if necessary\n",
            "Found annotations at '/Users/antonio/fiftyone/coco-2017/raw/instances_val2017.json'\n",
            "Sufficient images already downloaded\n",
            "Existing download of split 'validation' is sufficient\n",
            "Loading existing dataset 'evaluate-detections-tutorial'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        }
      ],
      "source": [
        "dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",\n",
        "    dataset_name=\"evaluate-detections-tutorial\",\n",
        "    # Take out the max_samples kwarg to get the full validation dataset\n",
        "    max_samples=10\n",
        ")\n",
        "# Changes made to this dataset will not persist in memory\n",
        "dataset.persistent = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "cb433",
        "id": "Y8PAw1kQ0AKd"
      },
      "source": [
        "## Dataset cloning\n",
        "\n",
        "Cloning a FiftyOne dataset before working with it is a best practice that creates a safe working copy while preserving your original data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellUniqueIdByVincent": "9a3e2",
        "id": "WjX3nGDxz_fE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded.\n"
          ]
        }
      ],
      "source": [
        "# Creates a full copy of the dataset (in case we want to go back to the original)\n",
        "working_dataset = dataset.clone()\n",
        "# Changes done to the clone of the dataset will persist in memory and appear in multiple Python sessions\n",
        "working_dataset.persistent = True\n",
        "print(\"Dataset loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellUniqueIdByVincent": "a3653",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsu890xQcKiL",
        "outputId": "2fb5e2bd-cd83-432a-c42d-ddc7ff13b001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing metadata...\n",
            " 100% |█████████████████| 200/200 [106.4ms elapsed, 0s remaining, 1.9K samples/s] \n"
          ]
        }
      ],
      "source": [
        "# Compute metadata on every image on the dataset\n",
        "# This includes height, width, size in bytes and type of the files\n",
        "# overwrite=True forces these values to be recomputed for samples with existing fields\n",
        "working_dataset.compute_metadata(overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellUniqueIdByVincent": "d9803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvtbHZrPcQNd",
        "outputId": "8991ce11-f1a7-44b4-bcef-c893388753bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<ImageMetadata: {\n",
            "    'size_bytes': 161811,\n",
            "    'mime_type': 'image/jpeg',\n",
            "    'width': 640,\n",
            "    'height': 426,\n",
            "    'num_channels': 3,\n",
            "}>\n"
          ]
        }
      ],
      "source": [
        "# Let's inspect the first sample of the dataset.\n",
        "# This will show its filepath, tags, metadata, and any existing fields like 'ground_truth'.\n",
        "# Let's check the metadata field that we just computed.\n",
        "print(working_dataset.first().metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellUniqueIdByVincent": "eced5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "4vBwuM_jvj-f",
        "outputId": "775c1a71-9715-4284-c2f4-22624009c198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Session launched. Run `session.show()` to open the App in a cell output.\n",
            "http://localhost:5151/\n"
          ]
        }
      ],
      "source": [
        "session = fo.launch_app(working_dataset, auto=False)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "c4ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "6AwIWFlFtkfF",
        "outputId": "f09c491c-a9a9-4f78-ba6c-d61bf0f07567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://localhost:5151/\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"t\":{\"$date\":\"2025-06-17T10:35:38.750Z\"},\"s\":\"I\",  \"c\":\"CONTROL\",  \"id\":20697,   \"ctx\":\"-\",\"msg\":\"Renamed existing log file\",\"attr\":{\"oldLogPath\":\"/Users/antonio/.fiftyone/var/lib/mongo/log/mongo.log\",\"newLogPath\":\"/Users/antonio/.fiftyone/var/lib/mongo/log/mongo.log.2025-06-17T10-35-38\"}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Subprocess ['/Users/antonio/Documents/Projects/GettingStartedWithFiftyOne/local_run/.venv/lib/python3.11/site-packages/fiftyone/db/bin/mongod', '--dbpath', '/Users/antonio/.fiftyone/var/lib/mongo', '--logpath', '/Users/antonio/.fiftyone/var/lib/mongo/log/mongo.log', '--port', '0', '--nounixsocket'] exited with error 1:\n",
            ")::SpecificImpl::call()\",\"s+\":\"168\"}\n",
            "  Frame: {\"a\":\"102DEBC38\",\"b\":\"1004CF000\",\"o\":\"291CC38\",\"s\":\"_ZN5mongo12_GLOBAL__N_17runFuncEPv\",\"C\":\"mongo::(anonymous namespace)::runFunc(void*)\",\"s+\":\"18\"}\n",
            "  Frame: {\"a\":\"7FF800C6F253\",\"b\":\"7FF800C69000\",\"o\":\"6253\",\"s\":\"_pthread_start\",\"s+\":\"63\"}\n",
            "  Frame: {\"a\":\"7FF800C6ABEF\",\"b\":\"7FF800C69000\",\"o\":\"1BEF\",\"s\":\"thread_start\",\"s+\":\"F\"}\n",
            "\"_ZZN5mongo15unique_functionIFvvEE8makeImplIZNS_9transport15ServiceExecutor8scheduleENS0_IFvNS_6StatusEEEEEUlvE_EEDaOT_EN12SpecificImpl4callEv\",\"C\":\"auto mongo::unique_function<void ()>::makeImpl<mongo::transport::ServiceExecutor::schedule(mongo::unique_function<void (mongo::Status)>)::'lambda'()>(mongo::transport::ServiceExecutor::schedule(mongo::unique_function<void (mongo::Status)>)::'lambda'()&&)::SpecificImpl::call()\",\"s+\":\"32\"}\n",
            "  Frame: {\"a\":\"102DEAF08\",\"b\":\"1004CF000\",\"o\":\"291BF08\",\"s\":\"_ZZN5mongo15unique_functionIFvvEE8makeImplIZNS_9transport26ServiceExecutorSynchronous12scheduleTaskES2_NS4_15ServiceExecutor13ScheduleFlagsEE3$_4EEDaOT_EN12SpecificImpl4callEv\",\"C\":\"auto mongo::unique_function<void ()>::makeImpl<mongo::transport::ServiceExecutorSynchronous::scheduleTask(mongo::unique_function<void ()>, mongo::transport::ServiceExecutor::ScheduleFlags)::$_4>(mongo::transport::ServiceExecutorSynchronous::scheduleTask(mongo::unique_function<void ()>, mongo::transport::ServiceExecutor::ScheduleFlags)::$_4&&id (mongo::Status)>::makeImpl<mongo::transport::ServiceStateMachine::Impl::scheduleNewLoop(mongo::Status)::$_5>(mongo::transport::ServiceStateMachine::Impl::scheduleNewLoop(mongo::Status)::$_5&&)::SpecificImpl::call(mongo::Status&&)\",\"s+\":\"60\"}\n",
            "  Frame: {\"a\":\"102DEB198\",\"b\":\"1004CF000\",\"o\":\"291C198\",\"s\":\"_ZZN5mongo15unique_functionIFvNS_6StatusEEE8makeImplIZNS_9transport26ServiceExecutorSynchronous18runOnDataAvailableERKNSt3__110shared_ptrINS5_7SessionEEES3_E3$_5EEDaOT_EN12SpecificImpl4callEOS1_\",\"C\":\"auto mongo::unique_function<void (mongo::Status)>::makeImpl<mongo::transport::ServiceExecutorSynchronous::runOnDataAvailable(std::__1::shared_ptr<mongo::transport::Session> const&, mongo::unique_function<void (mongo::Status)>)::$_5>(mongo::transport::ServiceExecutorSynchronous::runOnDataAvailable(std::__1::shared_ptr<mongo::transport::Session> const&, mongo::unique_function<void (mongo::Status)>)::$_5&&)::SpecificImpl::call(mongo::Status&&)\",\"s+\":\"38\"}\n",
            "  Frame: {\"a\":\"102DE79E2\",\"b\":\"1004CF000\",\"o\":\"29189E2\",\"s\":ptr<mongo::transport::Session>)::$_4>, void ()>::operator()()\",\"s+\":\"227\"}\n",
            "  Frame: {\"a\":\"1014B6E76\",\"b\":\"1004CF000\",\"o\":\"FE7E76\",\"s\":\"_ZN5mongo9transport19ServiceStateMachine4Impl14cleanupSessionERKNS_6StatusE\",\"C\":\"mongo::transport::ServiceStateMachine::Impl::cleanupSession(mongo::Status const&)\",\"s+\":\"1F6\"}\n",
            "  Frame: {\"a\":\"1014B6BF3\",\"b\":\"1004CF000\",\"o\":\"FE7BF3\",\"s\":\"_ZN5mongo9transport19ServiceStateMachine4Impl15scheduleNewLoopENS_6StatusE\",\"C\":\"mongo::transport::ServiceStateMachine::Impl::scheduleNewLoop(mongo::Status)\",\"s+\":\"463\"}\n",
            "  Frame: {\"a\":\"1014B73F5\",\"b\":\"1004CF000\",\"o\":\"FE83F5\",\"s\":\"_ZN5mongo9transport19ServiceStateMachine4Impl12startNewLoopERKNS_6StatusE\",\"C\":\"mongo::transport::ServiceStateMachine::Impl::startNewLoop(mongo::Status const&)\",\"s+\":\"415\"}\n",
            "  Frame: {\"a\":\"1014B9940\",\"b\":\"1004CF000\",\"o\":\"FEA940\",\"s\":\"_ZZN5mongo15unique_functionIFvNS_6StatusEEE8makeImplIZNS_9transport19ServiceStateMachine4Impl15scheduleNewLoopES1_E3$_5EEDaOT_EN12SpecificImpl4callEOS1_\",\"C\":\"auto mongo::unique_function<vo"
          ]
        }
      ],
      "source": [
        "## Create a view of the 10 random samples on our dataset\n",
        "# We launch the FiftyOne app to start visualizing the dataset.\n",
        "# fo.launch_app should be called only once per notebook.\n",
        "session.view = working_dataset.limit(10)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "33f9a",
        "id": "kK9knjkzDXIU"
      },
      "source": [
        "## Add predictions to our samples from two different object detection models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellUniqueIdByVincent": "36aba",
        "id": "Bawj4ThsEVfA"
      },
      "outputs": [],
      "source": [
        "retinanet_model = foz.load_zoo_model(\"retinanet-resnet50-fpn-coco-torch\")\n",
        "faster_rcnn_model = foz.load_zoo_model(\"faster-rcnn-resnet50-fpn-coco-torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellUniqueIdByVincent": "1ea13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qJv1jJSEXLz",
        "outputId": "0c49da5d-1508-48c4-dc40-5a25cf73f3ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████████| 200/200 [1.8m elapsed, 0s remaining, 2.0 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "# necessary to use multiprocessing in MacOS with PyTorch\n",
        "import multiprocessing as mp\n",
        "mp.set_start_method('fork', force=True)\n",
        "\n",
        "# Here we apply two different object detection models.\n",
        "# RetinaNet is a single shot detector (like YOLO), known for its speed.\n",
        "# Faster-RCNN is a two stage detector, known for its ability to detect objects\n",
        "# in a big variety of sizes and aspect ratios with relatively low fine-tuning.\n",
        "working_dataset.apply_model(retinanet_model, \n",
        "                            label_field=\"retinanet_predictions\", \n",
        "                            num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellUniqueIdByVincent": "26dcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████████| 200/200 [2.2m elapsed, 0s remaining, 1.7 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "working_dataset.apply_model(faster_rcnn_model, \n",
        "                            label_field=\"faster_rcnn_predictions\",\n",
        "                            num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellUniqueIdByVincent": "de7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "L6F0KE4nEhgj",
        "outputId": "84167471-036d-41c9-e6d1-85aaa4a8503e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://localhost:5151/\n"
          ]
        }
      ],
      "source": [
        "# session.refresh() keeps the data state the FiftyOne Python SDK and the FiftyOne app consistent\n",
        "session.refresh()\n",
        "# We can now see the predictions on the dataset\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellUniqueIdByVincent": "77a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "46X7Vi6UEzfo",
        "outputId": "ed92ecc5-23ae-4db7-db95-b292edd9d150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://5151-gpu-l4-s-3t0n5cjcytmb1-a.asia-southeast1-1.prod.colab.dev?polling=true\n"
          ]
        }
      ],
      "source": [
        "# Resets the session; the entire dataset will now be shown\n",
        "session.view = None\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellUniqueIdByVincent": "59f3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "fjkKPtB1F3N8",
        "outputId": "36a3e903-bf2f-4a02-def2-1b32f5035789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://5151-gpu-l4-s-3t0n5cjcytmb1-a.asia-southeast1-1.prod.colab.dev?polling=true\n"
          ]
        }
      ],
      "source": [
        "# Going back to showing the view\n",
        "session.view = working_dataset.view()\n",
        "session.refresh()\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "1c38f",
        "id": "nO6tua7HGKtR"
      },
      "source": [
        "Now try inspecting the predictions with confidence > 0.75"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "6dd41",
        "id": "8EtRLTYVG-77"
      },
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/predictions.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "51ca8",
        "id": "bd8BVqxkHKad"
      },
      "source": [
        "## Confidence thresholding through aggregations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellUniqueIdByVincent": "efd48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8ywxddxZjK7",
        "outputId": "8518f5eb-fd14-4391-db5f-b439ebd60077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.36016130447387695, 0.4785417914390564, 0.7015531063079834, 0.8853926062583923]\n"
          ]
        }
      ],
      "source": [
        "retinanet_quantiles = working_dataset.quantiles(\n",
        "    \"retinanet_predictions.detections.confidence\",\n",
        "    [0.25, 0.5, 0.75, 0.9],\n",
        ")\n",
        "print(retinanet_quantiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "cellUniqueIdByVincent": "34e1d",
        "id": "T0r2X42KHRcB"
      },
      "outputs": [],
      "source": [
        "high_conf_view = working_dataset.filter_labels(\"retinanet_predictions\",\n",
        "                                                F(\"confidence\") > retinanet_quantiles[-1],\n",
        "                                                only_matches=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "aedb5",
        "id": "XfphZjEOHdh_"
      },
      "source": [
        "Note the `only_matches=False` argument. When filtering labels, any samples that no longer contain labels would normally be removed from the view. However, this is not desired when performing evaluations since it can skew your results between views. We set `only_matches=False` so that all samples will be retained, even if some no longer contain labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "cellUniqueIdByVincent": "658f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goOclyruHhQT",
        "outputId": "3883476c-e850-42b6-de23-bc5c4e386b99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset:     2025.06.15.17.32.55.881728\n",
            "Media type:  image\n",
            "Num samples: 200\n",
            "Sample fields:\n",
            "    id:                      fiftyone.core.fields.ObjectIdField\n",
            "    filepath:                fiftyone.core.fields.StringField\n",
            "    tags:                    fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:                fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    created_at:              fiftyone.core.fields.DateTimeField\n",
            "    last_modified_at:        fiftyone.core.fields.DateTimeField\n",
            "    ground_truth:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    retinanet_predictions:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    faster_rcnn_predictions: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "View stages:\n",
            "    1. FilterLabels(field='retinanet_predictions', filter={'$gt': ['$$this.confidence', 0.8853926062583923]}, only_matches=False, trajectories=False)\n"
          ]
        }
      ],
      "source": [
        "# Print some information about the view\n",
        "print(high_conf_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "cellUniqueIdByVincent": "ee68e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OegCfpaAHmSj",
        "outputId": "d318b400-63bd-4dd9-a4a3-14185d9054b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Detections: {'detections': []}>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print a prediction from the view to verify that it has labels with confidence above the threshold\n",
        "sample = high_conf_view.first()\n",
        "sample.retinanet_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "4f76a",
        "id": "NotryRGDKmNW"
      },
      "outputs": [],
      "source": [
        "# Load high confidence view in the App\n",
        "session.view = high_conf_view\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "7eefa",
        "id": "zXO_9a6oLZTe"
      },
      "source": [
        "Try inspecting patches on the view\n",
        "\n",
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/inspecting_patches.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "87c65",
        "id": "fiCTnawjKnTF"
      },
      "source": [
        "## Evaluate predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "acae2",
        "id": "9NNmE83pL4Ga"
      },
      "outputs": [],
      "source": [
        "# Evaluate the predictions in the `faster_rcnn` field of our `high_conf_view`\n",
        "# with respect to the objects in the `ground_truth` field\n",
        "results = high_conf_view.evaluate_detections(\n",
        "    \"retinanet_predictions\",\n",
        "    gt_field=\"ground_truth\",\n",
        "    eval_key=\"eval\",\n",
        "    compute_mAP=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "aa6c9",
        "id": "3DcWl-EDL5Jd"
      },
      "outputs": [],
      "source": [
        "# Get the 10 most common classes in the dataset\n",
        "counts = working_dataset.count_values(\"ground_truth.detections.label\")\n",
        "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
        "\n",
        "# Print a classification report for the top-10 classes\n",
        "results.print_report(classes=classes_top10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "2dde2",
        "id": "ajfYElVXMBDP"
      },
      "outputs": [],
      "source": [
        "print(results.mAP())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "1c22a",
        "id": "UGhjHMVtML-f"
      },
      "outputs": [],
      "source": [
        "# install ipywidgets if needed for the interactive plot below\n",
        "!pip install 'ipywidgets>=8,<9'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "4f431",
        "id": "dP4JPVPDL-7n"
      },
      "outputs": [],
      "source": [
        "plot = results.plot_pr_curves(classes=[\"person\", \"car\"])\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "a7776",
        "id": "8dpR7eosMW4S"
      },
      "source": [
        "## Sample level analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "8fcbd",
        "id": "1A--63fNMaWT"
      },
      "outputs": [],
      "source": [
        "# Our dataset's schema now contains `eval_*` fields from a confusion matrix\n",
        "print(working_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "3e711",
        "id": "KOdEugOHO9xs"
      },
      "outputs": [],
      "source": [
        "# The dataset keeps track of the evaluations that we have run\n",
        "print(working_dataset.list_evaluations())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "5be31",
        "id": "xCqkfalVPIZM"
      },
      "outputs": [],
      "source": [
        "print(working_dataset.get_evaluation_info(\"eval\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "7dcf3",
        "id": "HTR8QO2uPR31"
      },
      "outputs": [],
      "source": [
        "# Load the view on which we ran the `eval` evaluation\n",
        "eval_view = working_dataset.load_evaluation_view(\"eval\")\n",
        "print(eval_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "458ad",
        "id": "o8EzkeZrMdYM"
      },
      "outputs": [],
      "source": [
        "# Our detections have helpful evaluation data on them\n",
        "sample = high_conf_view.first()\n",
        "sample.retinanet_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "d6c40",
        "id": "dkoSH1D8MbAF"
      },
      "outputs": [],
      "source": [
        "# View the `iscrowd` attribute on a ground truth object\n",
        "sample = working_dataset.first()\n",
        "print(sample.ground_truth.detections[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "7ec69",
        "id": "bBZmKE4BN7JQ"
      },
      "source": [
        "## Evaluation patches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "ae2e9",
        "id": "hnQqEcRXPm6W"
      },
      "source": [
        "So, now that we have a sense for the aggregate performance of our model, let's dive into sample-level analysis by creating an [evaluation view](https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-evaluation-patches).\n",
        "\n",
        "Any evaluation that you stored on your dataset can be used to generate an [evaluation view](https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-evaluation-patches) that is a patches view creating a sample for every true positive, false positive, and false negative in your dataset.\n",
        "Through this view, you can quickly filter and sort evaluated detections by their type (TP/FP/FN), evaluated IoU, and if they are matched to a crowd object.\n",
        "\n",
        "These evaluation views can be created through Python or directly in the App as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "c769a",
        "id": "-Fx0EvjVPcDX"
      },
      "outputs": [],
      "source": [
        "eval_patches = working_dataset.to_evaluation_patches(\"eval\")\n",
        "print(eval_patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "8f0dd",
        "id": "MFFVnezFPrEz"
      },
      "outputs": [],
      "source": [
        "# let's use this evaluation to find false positives with confidence above > .85\n",
        "session_view = high_conf_view\n",
        "print(session.url )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "b0c75",
        "id": "gE9-FIvNQ5Pj"
      },
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/false_positive.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "75216",
        "id": "sCLke7VaRtAY"
      },
      "source": [
        "## View with best performing cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "4ead1",
        "id": "-PSPhsHnR88M"
      },
      "outputs": [],
      "source": [
        "# Show samples with most true positives\n",
        "session.view = high_conf_view.sort_by(\"eval_tp\", reverse=True)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "b7db3",
        "id": "ihCEA2KaSHAy"
      },
      "source": [
        "## View with the worst performing cases by false positives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "97719",
        "id": "z_Xp3tstR-NL"
      },
      "outputs": [],
      "source": [
        "# Show samples with most false positives\n",
        "session.view = high_conf_view.sort_by(\"eval_fp\", reverse=True)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "c2f06",
        "id": "EK8mbOBdSQ9d"
      },
      "source": [
        "## View with the best performing cases by false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "254d1",
        "id": "h9slf4XWSX6F"
      },
      "outputs": [],
      "source": [
        "# Show samples with most false negatives\n",
        "session.view = high_conf_view.sort_by(\"eval_fn\", reverse=True)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "caae4",
        "id": "qCMZJcBDSagN"
      },
      "source": [
        "## Filtering by bounding box area"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "953d2",
        "id": "TTlArhXuSkPm"
      },
      "outputs": [],
      "source": [
        "# Compute metadata so we can reference image height/width in our view\n",
        "dataset.compute_metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "00eda",
        "id": "yCEC4s_nSme3"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Create an expression that will match objects whose bounding boxes have\n",
        "# area less than 32^2 pixels\n",
        "#\n",
        "# Bounding box format is [top-left-x, top-left-y, width, height]\n",
        "# with relative coordinates in [0, 1], so we multiply by image\n",
        "# dimensions to get pixel area\n",
        "#\n",
        "bbox_area = (\n",
        "    F(\"$metadata.width\") * F(\"bounding_box\")[2] *\n",
        "    F(\"$metadata.height\") * F(\"bounding_box\")[3]\n",
        ")\n",
        "small_boxes = bbox_area < 32 ** 2\n",
        "\n",
        "# Create a view that contains only small (and high confidence) predictions\n",
        "small_boxes_view = high_conf_view.filter_labels(\"retinanet_predictions\", small_boxes)\n",
        "\n",
        "session.view = small_boxes_view\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "2be10",
        "id": "zZgTtZObSpKj"
      },
      "outputs": [],
      "source": [
        "# Create a view that contains only small GT and predicted boxes\n",
        "small_boxes_eval_view = (\n",
        "    high_conf_view\n",
        "    .filter_labels(\"ground_truth\", small_boxes, only_matches=False)\n",
        "    .filter_labels(\"retinanet_predictions\", small_boxes, only_matches=False)\n",
        ")\n",
        "\n",
        "# Run evaluation\n",
        "small_boxes_results = small_boxes_eval_view.evaluate_detections(\n",
        "    \"retinanet_predictions\",\n",
        "    gt_field=\"ground_truth\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "baffa",
        "id": "hZURNr4GS5pQ"
      },
      "outputs": [],
      "source": [
        "# Get the 10 most common small object classes\n",
        "small_counts = small_boxes_eval_view.count_values(\"ground_truth.detections.label\")\n",
        "classes_top10_small = sorted(small_counts, key=counts.get, reverse=True)[:10]\n",
        "\n",
        "# Print a classification report for the top-10 small object classes\n",
        "small_boxes_results.print_report(classes=classes_top10_small)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "8e099",
        "id": "PUodNpp3TLlx"
      },
      "source": [
        "## Inspecting the crowd views"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "cfdf3",
        "id": "Ix1viEAcTAUd"
      },
      "outputs": [],
      "source": [
        "# View the `iscrowd` attribute on a ground truth object\n",
        "sample = working_dataset.first()\n",
        "print(sample.ground_truth.detections[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "0341f",
        "id": "JeX15hDlTEGD"
      },
      "outputs": [],
      "source": [
        "# Create a view that contains only samples for which at least one detection has\n",
        "# its iscrowd attribute set to 1\n",
        "crowded_images_view = high_conf_view.match(\n",
        "    F(\"ground_truth.detections\").filter(F(\"iscrowd\") == 1).length() > 0\n",
        ")\n",
        "\n",
        "session.view = crowded_images_view\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "c57d8",
        "id": "1lGHbQwjTP5f"
      },
      "outputs": [],
      "source": [
        "# Evaluating the crowd by the number of false positives\n",
        "session.view = crowded_images_view.sort_by(\"eval_fp\", reverse=True)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "f5eb0",
        "id": "DdR3T7rgUy2t"
      },
      "source": [
        "## Using the model to improve the dataset (active learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "9841f",
        "id": "oYjvUA63Uh7o"
      },
      "outputs": [],
      "source": [
        "# Tag all highly confident false positives as \"possibly-missing\"\n",
        "(\n",
        "    high_conf_view\n",
        "        .filter_labels(\"retinanet_predictions\", F(\"eval\") == \"fp\")\n",
        "        .select_fields(\"retinanet_predictions\")\n",
        "        .tag_labels(\"possibly-missing\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "1896d",
        "id": "PKcDI-_DVP0c"
      },
      "source": [
        "These tagged labels could then be sent off to our annotation provider of choice for review and addition to the ground truth labels. FiftyOne currently offers integrations for [Scale AI](https://voxel51.com/docs/fiftyone/api/fiftyone.utils.scale.html), [Labelbox](https://voxel51.com/docs/fiftyone/api/fiftyone.utils.labelbox.html), and [CVAT](https://voxel51.com/docs/fiftyone/api/fiftyone.types.dataset_types.html?highlight=cvat#fiftyone.types.dataset_types.CVATImageDataset).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "fb773",
        "id": "TddG37ygTwmB"
      },
      "outputs": [],
      "source": [
        "# Export all labels with the `possibly-missing` tag in CVAT format\n",
        "(\n",
        "    dataset\n",
        "        .select_labels(tags=[\"possibly-missing\"])\n",
        "        .export(\"./possibly_missing_labels\", fo.types.CVATImageDataset)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "6ba64",
        "id": "Uz4z1poBVLzx"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, we covered loading a dataset into FiftyOne and analyzing the performance of an out-of-the-box object detection model on the dataset.\n",
        "\n",
        "**So, what's the takeaway?**\n",
        "\n",
        "Aggregate evaluation results for an object detector are important, but they alone don't tell the whole story of a model's performance. It's critical to study the failure modes of your model so you can take the right actions to improve them.\n",
        "\n",
        "In this tutorial, we covered two types of analysis:\n",
        "\n",
        "- Analyzing the performance of your detector across different strata, like high confidence, small objects in crowded scenes\n",
        "- Inspecting the hardest samples in your dataset to diagnose the underlying issue, whether it be your detector or the ground truth annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "e162e",
        "id": "QRQvXyp-VZxa"
      },
      "source": [
        "## About this tutorial\n",
        "\n",
        "This tutorial is based on [FiftyOne's documentation](https://docs.voxel51.com/tutorials/evaluate_detections.html). You will notice a couple of minor changes.\n",
        "\n",
        "* Views for the app launch on their own window, this makes it easier for us to inspect the output of our views on the app.\n",
        "* We create a clone of the COCO dataset at the start of the notebook so that we can go back to its original state if we want\n",
        "* As an exercise I encourage to try our [integration with Ultralytics's YOLO] and compare it with RetinaNet and Faster RCNN(https://docs.voxel51.com/integrations/ultralytics.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellUniqueIdByVincent": "d5645",
        "id": "K3Z1BeHDZAG-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "vincent": {
      "sessionId": "eb87ef1ce8b7087663336699_2025-06-16T08-03-49-940Z"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
