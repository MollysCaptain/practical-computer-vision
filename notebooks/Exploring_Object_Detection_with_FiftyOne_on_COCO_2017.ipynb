{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andandandand/practical-computer-vision/blob/main/notebooks/Exploring_Object_Detection_with_FiftyOne_on_COCO_2017.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lemoi2vjMw5q"
      },
      "source": [
        "# Exploring Object Detection Performance with FiftyOne\n",
        "\n",
        "In this notebook we examine the performance of a pretrained [RetinaNet](https://arxiv.org/abs/1708.02002) on the [COCO 2017 validation set](https://cocodataset.org/#home), through the open source [FiftyOne](https://github.com/voxel51/fiftyone) SDK and visualization app.\n",
        "\n",
        "It covers the following concepts:\n",
        "\n",
        "- Loading a dataset with ground truth labels [into FiftyOne](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/index.html)\n",
        "- [Adding model predictions](https://voxel51.com/docs/fiftyone/recipes/adding_detections.html) to your dataset\n",
        "- [Evaluating your model](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#detections) using FiftyOne's evaluation API\n",
        "- Viewing the best and worst performing samples in your dataset\n",
        "\n",
        "**So, what's the takeaway?**\n",
        "\n",
        "Aggregate measures of performance like [mean Average Precision](https://kili-technology.com/data-labeling/machine-learning/mean-average-precision-map-a-complete-guide) don't give us the full picture of your detection model. In practice, the limiting factor on your model's performance is often data quality issues that we need to **see** to address. FiftyOne is designed to make it easy to do just that.\n",
        "\n",
        "## Inspecting your datasets\n",
        "\n",
        "Running the workflow presented here on your ML projects will help you to understand the current failure modes (edge cases) of your model and how to fix them, including:\n",
        "\n",
        "- Identifying scenarios that require additional training samples in order to boost your model's performance\n",
        "- Deciding whether your ground truth annotations have errors/weaknesses that need to be corrected before any subsequent model training will be profitable\n",
        "\n",
        "\n",
        "This walkthrough demonstrates how to use FiftyOne to perform hands-on evaluation of your detection model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmw0PeIsMruf"
      },
      "source": [
        "## Install FiftyOne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bmi7POz6UpHq"
      },
      "outputs": [],
      "source": [
        "# Install the library, you will need to uncomment this on Colab\n",
        "#!pip install fiftyone==1.5.2 > /dev/null\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofBUqpYvV8te",
        "outputId": "e155bc71-e5cd-46ee-91ac-b7851f9b451b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FiftyOne version: 1.5.2\n"
          ]
        }
      ],
      "source": [
        "#Check installed versions\n",
        "import fiftyone as fo\n",
        "print(f\"FiftyOne version: {fo.__version__}\")\n",
        "\n",
        "import fiftyone.zoo as foz\n",
        "import fiftyone.brain as fob \n",
        "from fiftyone import ViewField as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7fm78guiRlU"
      },
      "source": [
        "## Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0nwZLduUx8t",
        "outputId": "7ccba804-08f1-4e5c-e52b-ac9d538d54da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading split 'validation' to '/fiftyone/zoo/datasets/coco-2017/validation' if necessary\n",
            "Downloading annotations to '/fiftyone/zoo/datasets/coco-2017/tmp-download/annotations_trainval2017.zip'\n",
            " 100% |██████|    1.9Gb/1.9Gb [3.6m elapsed, 0s remaining, 9.4Mb/s]       \n",
            "Extracting annotations to '/fiftyone/zoo/datasets/coco-2017/raw/instances_val2017.json'\n",
            "Downloading images to '/fiftyone/zoo/datasets/coco-2017/tmp-download/val2017.zip'\n",
            " 100% |██████|    6.1Gb/6.1Gb [30.2s elapsed, 0s remaining, 215.3Mb/s]      \n",
            "Extracting images to '/fiftyone/zoo/datasets/coco-2017/validation/data'\n",
            "Writing annotations to '/fiftyone/zoo/datasets/coco-2017/validation/labels.json'\n",
            "Dataset info written to '/fiftyone/zoo/datasets/coco-2017/info.json'\n",
            "Loading 'coco-2017' split 'validation'\n",
            " 100% |███████████████| 5000/5000 [9.9s elapsed, 0s remaining, 508.2 samples/s]      \n",
            "Dataset 'evaluate-detections-tutorial' created\n",
            "Dataset loaded.\n",
            "<Sample: {\n",
            "    'id': '6838b09acf5d4afce388ec8f',\n",
            "    'media_type': 'image',\n",
            "    'filepath': '/fiftyone/zoo/datasets/coco-2017/validation/data/000000000139.jpg',\n",
            "    'tags': ['validation'],\n",
            "    'metadata': <ImageMetadata: {\n",
            "        'size_bytes': None,\n",
            "        'mime_type': None,\n",
            "        'width': 640,\n",
            "        'height': 426,\n",
            "        'num_channels': None,\n",
            "    }>,\n",
            "    'created_at': datetime.datetime(2025, 5, 29, 19, 8, 20, 912000),\n",
            "    'last_modified_at': datetime.datetime(2025, 5, 29, 19, 8, 20, 912000),\n",
            "    'ground_truth': <Detections: {\n",
            "        'detections': [\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec7b',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'potted plant',\n",
            "                'bounding_box': [\n",
            "                    0.37028125,\n",
            "                    0.3345305164319249,\n",
            "                    0.038593749999999996,\n",
            "                    0.16314553990610328,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec7c',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'tv',\n",
            "                'bounding_box': [\n",
            "                    0.010984375000000001,\n",
            "                    0.39380281690140845,\n",
            "                    0.23331249999999998,\n",
            "                    0.22269953051643193,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'electronic',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec7d',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'tv',\n",
            "                'bounding_box': [\n",
            "                    0.8706406250000001,\n",
            "                    0.491056338028169,\n",
            "                    0.127109375,\n",
            "                    0.18481220657276995,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'electronic',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec7e',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'chair',\n",
            "                'bounding_box': [\n",
            "                    0.56090625,\n",
            "                    0.5118544600938968,\n",
            "                    0.0875,\n",
            "                    0.24138497652582158,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec7f',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'chair',\n",
            "                'bounding_box': [\n",
            "                    0.454203125,\n",
            "                    0.5117370892018779,\n",
            "                    0.096609375,\n",
            "                    0.2311737089201878,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec80',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'chair',\n",
            "                'bounding_box': [\n",
            "                    0.645625,\n",
            "                    0.5234976525821596,\n",
            "                    0.047140625000000005,\n",
            "                    0.19098591549295774,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec81',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'chair',\n",
            "                'bounding_box': [\n",
            "                    0.4959375,\n",
            "                    0.5146478873239437,\n",
            "                    0.03371875,\n",
            "                    0.02720657276995305,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec82',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'person',\n",
            "                'bounding_box': [\n",
            "                    0.645,\n",
            "                    0.3699765258215963,\n",
            "                    0.082890625,\n",
            "                    0.3239671361502347,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'person',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec83',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'person',\n",
            "                'bounding_box': [\n",
            "                    0.600671875,\n",
            "                    0.40424882629107983,\n",
            "                    0.023625,\n",
            "                    0.08389671361502347,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'person',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec84',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'microwave',\n",
            "                'bounding_box': [\n",
            "                    0.80034375,\n",
            "                    0.482981220657277,\n",
            "                    0.02303125,\n",
            "                    0.037488262910798126,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'appliance',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec85',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'refrigerator',\n",
            "                'bounding_box': [\n",
            "                    0.77046875,\n",
            "                    0.40924882629107984,\n",
            "                    0.031703125,\n",
            "                    0.2542488262910798,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'appliance',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec86',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'book',\n",
            "                'bounding_box': [\n",
            "                    0.944953125,\n",
            "                    0.7180516431924883,\n",
            "                    0.02240625,\n",
            "                    0.10730046948356808,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec87',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'book',\n",
            "                'bounding_box': [\n",
            "                    0.9581875,\n",
            "                    0.7235680751173709,\n",
            "                    0.020125,\n",
            "                    0.10901408450704225,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec88',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'clock',\n",
            "                'bounding_box': [\n",
            "                    0.699640625,\n",
            "                    0.2843192488262911,\n",
            "                    0.021828125,\n",
            "                    0.05136150234741784,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec89',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'vase',\n",
            "                'bounding_box': [\n",
            "                    0.8579062499999999,\n",
            "                    0.7263615023474178,\n",
            "                    0.0573125,\n",
            "                    0.2104929577464789,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec8a',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'vase',\n",
            "                'bounding_box': [\n",
            "                    0.5480625,\n",
            "                    0.4902347417840376,\n",
            "                    0.017765625,\n",
            "                    0.05293427230046949,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec8b',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'chair',\n",
            "                'bounding_box': [\n",
            "                    0.644140625,\n",
            "                    0.514131455399061,\n",
            "                    0.015046875000000001,\n",
            "                    0.029389671361502348,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec8c',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'vase',\n",
            "                'bounding_box': [\n",
            "                    0.37693750000000004,\n",
            "                    0.4577230046948357,\n",
            "                    0.022218750000000002,\n",
            "                    0.04138497652582159,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec8d',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'vase',\n",
            "                'bounding_box': [\n",
            "                    0.526234375,\n",
            "                    0.46830985915492956,\n",
            "                    0.015203125000000001,\n",
            "                    0.039272300469483566,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'indoor',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '6838b09acf5d4afce388ec8e',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'dining table',\n",
            "                'bounding_box': [\n",
            "                    0.5018906249999999,\n",
            "                    0.5427699530516432,\n",
            "                    0.19618750000000001,\n",
            "                    0.20875586854460096,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'mask_path': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'furniture',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "        ],\n",
            "    }>,\n",
            "}>\n"
          ]
        }
      ],
      "source": [
        "dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",\n",
        "    dataset_name=\"evaluate-detections-tutorial\",\n",
        ")\n",
        "dataset.persistent = True\n",
        "dataset_clone = dataset.clone()\n",
        "dataset_clone.persistent = True\n",
        "\n",
        "print(\"Dataset loaded.\")\n",
        "\n",
        "# Let's inspect the first sample of the dataset.\n",
        "# This will show its filepath, tags, metadata, and any existing fields like 'ground_truth'.\n",
        "print(dataset_clone.first())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK9knjkzDXIU"
      },
      "source": [
        "# Choose a random subset of samples to add predictions to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Mm8psUP-DbTV"
      },
      "outputs": [],
      "source": [
        "predictions_view = dataset_clone.take(100, seed=51)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bawj4ThsEVfA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading model from 'https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth'...\n",
            " 100% |██████|    1.0Gb/1.0Gb [9.7s elapsed, 0s remaining, 89.7Mb/s]       \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth\" to /root/.cache/torch/hub/checkpoints/retinanet_resnet50_fpn_coco-eeacb38b.pth\n",
            "100%|██████████| 130M/130M [00:01<00:00, 69.2MB/s] \n"
          ]
        }
      ],
      "source": [
        "model = foz.load_zoo_model(\"retinanet-resnet50-fpn-coco-torch\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qJv1jJSEXLz",
        "outputId": "18713da3-0450-416c-93e6-e1a302c03a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████████| 100/100 [2.8m elapsed, 0s remaining, 0.6 samples/s]    \n"
          ]
        }
      ],
      "source": [
        "predictions_view.apply_model(model, label_field=\"predictions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6F0KE4nEhgj",
        "outputId": "165c32c8-9faf-42c4-8f70-371362a29b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Session launched. Run `session.show()` to open the App in a cell output.\n",
            "\n",
            "Welcome to\n",
            "\n",
            "███████╗██╗███████╗████████╗██╗   ██╗ ██████╗ ███╗   ██╗███████╗\n",
            "██╔════╝██║██╔════╝╚══██╔══╝╚██╗ ██╔╝██╔═══██╗████╗  ██║██╔════╝\n",
            "█████╗  ██║█████╗     ██║    ╚████╔╝ ██║   ██║██╔██╗ ██║█████╗\n",
            "██╔══╝  ██║██╔══╝     ██║     ╚██╔╝  ██║   ██║██║╚██╗██║██╔══╝\n",
            "██║     ██║██║        ██║      ██║   ╚██████╔╝██║ ╚████║███████╗\n",
            "╚═╝     ╚═╝╚═╝        ╚═╝      ╚═╝    ╚═════╝ ╚═╝  ╚═══╝╚══════╝ v1.5.2\n",
            "\n",
            "If you're finding FiftyOne helpful, here's how you can get involved:\n",
            "\n",
            "|\n",
            "|  ⭐⭐⭐ Give the project a star on GitHub ⭐⭐⭐\n",
            "|  https://github.com/voxel51/fiftyone\n",
            "|\n",
            "|  🚀🚀🚀 Join the FiftyOne Discord community 🚀🚀🚀\n",
            "|  https://community.voxel51.com/\n",
            "|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "session = fo.launch_app(predictions_view, auto=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "zpl_FN2iEebK",
        "outputId": "fc8ed702-0442-4f3c-c7e0-167ee3226c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "# Shows the predictions on the view only\n",
        "session.view = predictions_view\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "46X7Vi6UEzfo",
        "outputId": "9eef60b3-14a4-44bb-9151-9fe369192f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "# Resets the session; the entire dataset will now be shown\n",
        "session.view = None\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "fjkKPtB1F3N8",
        "outputId": "5ad9a733-69af-4583-a7ad-c394cc452458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "# Going back to showing the view\n",
        "session.view = predictions_view\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO6tua7HGKtR"
      },
      "source": [
        "Now try inspecting the predictions with confidence > 0.75"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EtRLTYVG-77"
      },
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/predictions.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd8BVqxkHKad"
      },
      "source": [
        "## Confidence threshold through the SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T0r2X42KHRcB"
      },
      "outputs": [],
      "source": [
        "# Only contains detections with confidence >= 0.75\n",
        "high_conf_view = predictions_view.filter_labels(\"predictions\",\n",
        "                                                F(\"confidence\") > 0.75,\n",
        "                                                only_matches=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfphZjEOHdh_"
      },
      "source": [
        "Note the `only_matches=False` argument. When filtering labels, any samples that no longer contain labels would normally be removed from the view. However, this is not desired when performing evaluations since it can skew your results between views. We set `only_matches=False` so that all samples will be retained, even if some no longer contain labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goOclyruHhQT",
        "outputId": "54145199-cebe-46d5-8ead-70fde18f4224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset:     2025.05.29.19.08.20.907977\n",
            "Media type:  image\n",
            "Num samples: 100\n",
            "Sample fields:\n",
            "    id:               fiftyone.core.fields.ObjectIdField\n",
            "    filepath:         fiftyone.core.fields.StringField\n",
            "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    created_at:       fiftyone.core.fields.DateTimeField\n",
            "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
            "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    predictions:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "View stages:\n",
            "    1. Take(size=100, seed=51)\n",
            "    2. FilterLabels(field='predictions', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)\n"
          ]
        }
      ],
      "source": [
        "# Print some information about the view\n",
        "print(high_conf_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OegCfpaAHmSj",
        "outputId": "afbe79e9-f165-4cb8-b8f1-de3b88922e56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<SampleView: {\n",
              "    'id': '6838b09ecf5d4afce38923e1',\n",
              "    'media_type': 'image',\n",
              "    'filepath': '/fiftyone/zoo/datasets/coco-2017/validation/data/000000189475.jpg',\n",
              "    'tags': ['validation'],\n",
              "    'metadata': <ImageMetadata: {\n",
              "        'size_bytes': None,\n",
              "        'mime_type': None,\n",
              "        'width': 500,\n",
              "        'height': 375,\n",
              "        'num_channels': None,\n",
              "    }>,\n",
              "    'created_at': datetime.datetime(2025, 5, 29, 19, 8, 20, 912000),\n",
              "    'last_modified_at': datetime.datetime(2025, 5, 29, 19, 8, 36, 511000),\n",
              "    'ground_truth': <Detections: {\n",
              "        'detections': [\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892284',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'bottle',\n",
              "                'bounding_box': [0.2356, 0.64016, 0.1394, 0.3390933333333333],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892285',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'bottle',\n",
              "                'bounding_box': [\n",
              "                    0.32232,\n",
              "                    0.8236266666666667,\n",
              "                    0.061079999999999995,\n",
              "                    0.17637333333333333,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892286',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'chair',\n",
              "                'bounding_box': [0.67662, 0.43829333333333337, 0.11938, 0.25656],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'furniture',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892287',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'chair',\n",
              "                'bounding_box': [0.39696, 0.46936, 0.12006, 0.32330666666666663],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'furniture',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892288',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'chair',\n",
              "                'bounding_box': [\n",
              "                    0.43092,\n",
              "                    0.38186666666666663,\n",
              "                    0.0482,\n",
              "                    0.10117333333333332,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'furniture',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892289',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'cup',\n",
              "                'bounding_box': [\n",
              "                    0.72048,\n",
              "                    0.6510933333333333,\n",
              "                    0.08070000000000001,\n",
              "                    0.15648,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389228a',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'cup',\n",
              "                'bounding_box': [0.8132, 0.58712, 0.07468000000000001, 0.18888],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389228b',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'cup',\n",
              "                'bounding_box': [\n",
              "                    0.04682,\n",
              "                    0.8885866666666667,\n",
              "                    0.07994,\n",
              "                    0.11013333333333332,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389228c',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'knife',\n",
              "                'bounding_box': [\n",
              "                    0.40036,\n",
              "                    0.8500266666666666,\n",
              "                    0.22828,\n",
              "                    0.04573333333333333,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389228d',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'pizza',\n",
              "                'bounding_box': [\n",
              "                    0.50314,\n",
              "                    0.8858133333333333,\n",
              "                    0.13016,\n",
              "                    0.05298666666666667,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'food',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389228e',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [0.00664, 0.05722666666666667, 0.42968, 0.88192],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389228f',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [\n",
              "                    0.4618,\n",
              "                    0.21797333333333332,\n",
              "                    0.26627999999999996,\n",
              "                    0.5640533333333334,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892290',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [0.4736, 0.0472, 0.16348, 0.36402666666666667],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892291',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [0.64598, 0.1792, 0.062079999999999996, 0.17672],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892292',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [0.80198, 0.15288, 0.06306, 0.18304],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892293',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [\n",
              "                    0.81404,\n",
              "                    0.08989333333333334,\n",
              "                    0.18034,\n",
              "                    0.33258666666666664,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892294',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [\n",
              "                    0.7923600000000001,\n",
              "                    0.24058666666666667,\n",
              "                    0.20764,\n",
              "                    0.3811733333333333,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892295',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'cup',\n",
              "                'bounding_box': [\n",
              "                    0.33446,\n",
              "                    0.6768000000000001,\n",
              "                    0.07601999999999999,\n",
              "                    0.27928000000000003,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892296',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'cup',\n",
              "                'bounding_box': [0.91012, 0.6584266666666666, 0.08988, 0.32808],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892297',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'knife',\n",
              "                'bounding_box': [\n",
              "                    0.6624800000000001,\n",
              "                    0.9010933333333334,\n",
              "                    0.16726,\n",
              "                    0.07042666666666667,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892298',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'potted plant',\n",
              "                'bounding_box': [\n",
              "                    0.34866,\n",
              "                    0.07706666666666666,\n",
              "                    0.15292,\n",
              "                    0.27154666666666666,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'furniture',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce3892299',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'dining table',\n",
              "                'bounding_box': [0.55956, 0.6045066666666666, 0.43482, 0.27864],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'furniture',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389229a',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'dining table',\n",
              "                'bounding_box': [\n",
              "                    0.40618,\n",
              "                    0.7348266666666666,\n",
              "                    0.32022,\n",
              "                    0.11010666666666666,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'furniture',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389229b',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'refrigerator',\n",
              "                'bounding_box': [\n",
              "                    0.72356,\n",
              "                    0.1801333333333333,\n",
              "                    0.09631999999999999,\n",
              "                    0.16778666666666667,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'appliance',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389229c',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'vase',\n",
              "                'bounding_box': [0.41544, 0.17218666666666665, 0.07192, 0.17792],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'indoor',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389229d',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'bottle',\n",
              "                'bounding_box': [\n",
              "                    0.12376000000000001,\n",
              "                    0.7867733333333334,\n",
              "                    0.09184,\n",
              "                    0.15378666666666668,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389229e',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'fork',\n",
              "                'bounding_box': [\n",
              "                    0.40112000000000003,\n",
              "                    0.8954933333333334,\n",
              "                    0.15272,\n",
              "                    0.04328,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce389229f',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'knife',\n",
              "                'bounding_box': [\n",
              "                    0.67034,\n",
              "                    0.8882933333333334,\n",
              "                    0.11276,\n",
              "                    0.03930666666666667,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce38922a0',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'chair',\n",
              "                'bounding_box': [\n",
              "                    0.00726,\n",
              "                    0.6493599999999999,\n",
              "                    0.02114,\n",
              "                    0.12178666666666667,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'furniture',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce38922a1',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'potted plant',\n",
              "                'bounding_box': [\n",
              "                    0.71282,\n",
              "                    0.06269333333333334,\n",
              "                    0.14334,\n",
              "                    0.12418666666666667,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'furniture',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce38922a2',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'vase',\n",
              "                'bounding_box': [0.774, 0.13805333333333333, 0.0338, 0.04048],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'indoor',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce38922a3',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [\n",
              "                    0.00152,\n",
              "                    0.22912000000000002,\n",
              "                    0.1026,\n",
              "                    0.48050666666666664,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce38922a4',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [0.34146, 0.26464, 0.10024, 0.20906666666666668],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce38922a5',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [\n",
              "                    0.7034,\n",
              "                    0.26882666666666666,\n",
              "                    0.12686,\n",
              "                    0.18237333333333333,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce38922a6',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [\n",
              "                    0.04622,\n",
              "                    0.18869333333333335,\n",
              "                    0.06552,\n",
              "                    0.10354666666666666,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'person',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b09ecf5d4afce38922a7',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'cup',\n",
              "                'bounding_box': [\n",
              "                    0.74936,\n",
              "                    0.5237333333333334,\n",
              "                    0.07828,\n",
              "                    0.21530666666666665,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': None,\n",
              "                'index': None,\n",
              "                'supercategory': 'kitchen',\n",
              "                'iscrowd': 0,\n",
              "            }>,\n",
              "        ],\n",
              "    }>,\n",
              "    'predictions': <Detections: {\n",
              "        'detections': [\n",
              "            <Detection: {\n",
              "                'id': '6838b0b4cf5d4afce3898fb1',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [\n",
              "                    0.006261056289076805,\n",
              "                    0.07051300257444382,\n",
              "                    0.43123242259025574,\n",
              "                    0.8487465977668762,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': 0.9155575037002563,\n",
              "                'index': None,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b0b4cf5d4afce3898fb2',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [\n",
              "                    0.4535544812679291,\n",
              "                    0.21825151145458221,\n",
              "                    0.26171988248825073,\n",
              "                    0.5650441646575928,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': 0.8538865447044373,\n",
              "                'index': None,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b0b4cf5d4afce3898fb3',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'person',\n",
              "                'bounding_box': [\n",
              "                    0.7875495553016663,\n",
              "                    0.23827101290225983,\n",
              "                    0.21245044469833374,\n",
              "                    0.37890249490737915,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': 0.7964414358139038,\n",
              "                'index': None,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b0b4cf5d4afce3898fb4',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'cup',\n",
              "                'bounding_box': [\n",
              "                    0.9101207852363586,\n",
              "                    0.6620017290115356,\n",
              "                    0.08987921476364136,\n",
              "                    0.33037418127059937,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': 0.7927656173706055,\n",
              "                'index': None,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b0b4cf5d4afce3898fb5',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'cup',\n",
              "                'bounding_box': [\n",
              "                    0.7955495715141296,\n",
              "                    0.5864943861961365,\n",
              "                    0.0879906639456749,\n",
              "                    0.18077009916305542,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': 0.7653785347938538,\n",
              "                'index': None,\n",
              "            }>,\n",
              "            <Detection: {\n",
              "                'id': '6838b0b4cf5d4afce3898fb6',\n",
              "                'attributes': {},\n",
              "                'tags': [],\n",
              "                'label': 'cup',\n",
              "                'bounding_box': [\n",
              "                    0.04528123512864113,\n",
              "                    0.8894562721252441,\n",
              "                    0.08248679339885712,\n",
              "                    0.11054369807243347,\n",
              "                ],\n",
              "                'mask': None,\n",
              "                'mask_path': None,\n",
              "                'confidence': 0.7589644193649292,\n",
              "                'index': None,\n",
              "            }>,\n",
              "        ],\n",
              "    }>,\n",
              "}>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print a prediction from the view to verify that its confidence is > 0.75\n",
        "sample = high_conf_view.first()\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "NotryRGDKmNW",
        "outputId": "7606d8f5-f07e-450b-aee6-4847737cdd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "# Load high confidence view in the App\n",
        "session.view = high_conf_view\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXO_9a6oLZTe"
      },
      "source": [
        "Try inspecting patches on the view\n",
        "\n",
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/inspecting_patches.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiCTnawjKnTF"
      },
      "source": [
        "## Evaluate predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NNmE83pL4Ga",
        "outputId": "57b317c4-4908-42a3-a628-ec03a39f8ce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating detections...\n",
            " 100% |█████████████████| 100/100 [520.4ms elapsed, 0s remaining, 192.2 samples/s]      \n",
            "Performing IoU sweep...\n",
            " 100% |█████████████████| 100/100 [394.3ms elapsed, 0s remaining, 253.6 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "# Evaluate the predictions in the `faster_rcnn` field of our `high_conf_view`\n",
        "# with respect to the objects in the `ground_truth` field\n",
        "results = high_conf_view.evaluate_detections(\n",
        "    \"predictions\",\n",
        "    gt_field=\"ground_truth\",\n",
        "    eval_key=\"eval\",\n",
        "    compute_mAP=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DcWl-EDL5Jd",
        "outputId": "e1d52f86-5757-41fb-84cc-5909afca186e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "       person       0.99      0.40      0.57       229\n",
            "          car       0.92      0.29      0.44        38\n",
            "        chair       1.00      0.11      0.20        44\n",
            "         book       0.00      0.00      0.00        37\n",
            "       bottle       1.00      0.10      0.18        20\n",
            "          cup       1.00      0.26      0.42        19\n",
            " dining table       1.00      0.11      0.19        19\n",
            "traffic light       0.00      0.00      0.00        25\n",
            "         bowl       0.00      0.00      0.00         9\n",
            "      handbag       0.00      0.00      0.00        14\n",
            "\n",
            "    micro avg       0.97      0.26      0.40       454\n",
            "    macro avg       0.59      0.13      0.20       454\n",
            " weighted avg       0.80      0.26      0.38       454\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the 10 most common classes in the dataset\n",
        "counts = dataset_clone.count_values(\"ground_truth.detections.label\")\n",
        "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
        "\n",
        "# Print a classification report for the top-10 classes\n",
        "results.print_report(classes=classes_top10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajfYElVXMBDP",
        "outputId": "ed1a8554-bd98-4837-d933-59a519142316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3034670744932542\n"
          ]
        }
      ],
      "source": [
        "print(results.mAP())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UGhjHMVtML-f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipywidgets<9,>=8 in /opt/.fiftyone-venv/lib/python3.11/site-packages (8.1.7)\n",
            "Requirement already satisfied: comm>=0.1.3 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipywidgets<9,>=8) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipywidgets<9,>=8) (8.31.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipywidgets<9,>=8) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipywidgets<9,>=8) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipywidgets<9,>=8) (3.0.15)\n",
            "Requirement already satisfied: decorator in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=8) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=8) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=8) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=8) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=8) (3.0.48)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=8) (2.18.0)\n",
            "Requirement already satisfied: stack_data in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=8) (0.6.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=8) (4.12.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets<9,>=8) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets<9,>=8) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /opt/.fiftyone-venv/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets<9,>=8) (0.2.13)\n",
            "Requirement already satisfied: executing>=1.2.0 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets<9,>=8) (2.1.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /opt/.fiftyone-venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets<9,>=8) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /opt/.fiftyone-venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets<9,>=8) (0.2.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# install ipywidgets if needed for the interactive plot below\n",
        "!pip install 'ipywidgets>=8,<9'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "dP4JPVPDL-7n",
        "outputId": "39c45449-1f70-4666-f95a-8426eb2dd309"
      },
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb21fb7246c84b09a89a30c58b255008",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FigureWidget({\n",
              "    'data': [{'customdata': array([0.99218518, 0.98963709, 0.98864924, 0.98567861, 0.98375748, 0.97796589,\n",
              "                                   0.97225765, 0.97107594, 0.96842679, 0.95127236, 0.869515  , 0.867999  ,\n",
              "                                   0.8626564 , 0.85811699, 0.84844059, 0.84236296, 0.83271847, 0.82672042,\n",
              "                                   0.82146986, 0.81599904, 0.81177319, 0.8047875 , 0.79303241, 0.71254991,\n",
              "                                   0.70864769, 0.70561459, 0.69964364, 0.6886519 , 0.68341516, 0.67957386,\n",
              "                                   0.67195178, 0.66524132, 0.65525721, 0.57322136, 0.55930566, 0.55193307,\n",
              "                                   0.54647251, 0.53574771, 0.45811466, 0.37977147, 0.30017221, 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        ]),\n",
              "              'hovertemplate': ('<b>class: %{text}</b><br>recal' ... 'customdata:.3f}<extra></extra>'),\n",
              "              'line': {'color': '#3366CC'},\n",
              "              'mode': 'lines',\n",
              "              'name': 'person (AP = 0.326)',\n",
              "              'text': array(['person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
              "                             'person', 'person', 'person'], dtype='<U6'),\n",
              "              'type': 'scatter',\n",
              "              'uid': '0c3b2999-1a6c-43a7-bdd3-14e6f891e65f',\n",
              "              'x': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
              "                          0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22, 0.23,\n",
              "                          0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33, 0.34, 0.35,\n",
              "                          0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47,\n",
              "                          0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59,\n",
              "                          0.6 , 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7 , 0.71,\n",
              "                          0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83,\n",
              "                          0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95,\n",
              "                          0.96, 0.97, 0.98, 0.99, 1.  ]),\n",
              "              'y': array([1.        , 0.92777778, 0.91622222, 0.91622222, 0.91622222, 0.91171802,\n",
              "                          0.91171802, 0.91084656, 0.91037037, 0.89800195, 0.86563307, 0.86563307,\n",
              "                          0.85534267, 0.85168566, 0.85168566, 0.85049703, 0.84039602, 0.83843354,\n",
              "                          0.83801839, 0.83744147, 0.83744147, 0.83645749, 0.83275492, 0.77461538,\n",
              "                          0.77461538, 0.77461538, 0.77461538, 0.77461538, 0.77461538, 0.77461538,\n",
              "                          0.77271605, 0.77235294, 0.77089888, 0.69      , 0.68919118, 0.68816176,\n",
              "                          0.68633987, 0.68542484, 0.59222222, 0.49227106, 0.3956044 , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        ])},\n",
              "             {'customdata': array([0.92649621, 0.92174684, 0.92174684, 0.81172522, 0.81172522, 0.81172522,\n",
              "                                   0.80436578, 0.80436578, 0.79227933, 0.79227933, 0.79227933, 0.78023425,\n",
              "                                   0.78023425, 0.78023425, 0.77171291, 0.77171291, 0.68164473, 0.68164473,\n",
              "                                   0.68164473, 0.58010086, 0.58010086, 0.58010086, 0.5026875 , 0.5026875 ,\n",
              "                                   0.48594003, 0.48594003, 0.48594003, 0.30216179, 0.30216179, 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                                   0.        , 0.        , 0.        , 0.        , 0.        ]),\n",
              "              'hovertemplate': ('<b>class: %{text}</b><br>recal' ... 'customdata:.3f}<extra></extra>'),\n",
              "              'line': {'color': '#DC3912'},\n",
              "              'mode': 'lines',\n",
              "              'name': 'car (AP = 0.201)',\n",
              "              'text': array(['car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
              "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
              "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
              "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
              "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
              "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
              "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
              "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
              "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
              "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
              "                             'car'], dtype='<U3'),\n",
              "              'type': 'scatter',\n",
              "              'uid': '86fd6ab8-6ad0-440c-9c69-2a1331e98889',\n",
              "              'x': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
              "                          0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22, 0.23,\n",
              "                          0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33, 0.34, 0.35,\n",
              "                          0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47,\n",
              "                          0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59,\n",
              "                          0.6 , 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7 , 0.71,\n",
              "                          0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83,\n",
              "                          0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95,\n",
              "                          0.96, 0.97, 0.98, 0.99, 1.  ]),\n",
              "              'y': array([0.91666667, 0.91666667, 0.91666667, 0.86666667, 0.86666667, 0.86666667,\n",
              "                          0.86666667, 0.86666667, 0.76666667, 0.76666667, 0.76666667, 0.76      ,\n",
              "                          0.76      , 0.76      , 0.73333333, 0.73333333, 0.67333333, 0.67333333,\n",
              "                          0.67333333, 0.6       , 0.6       , 0.6       , 0.53333333, 0.53333333,\n",
              "                          0.53333333, 0.53333333, 0.53333333, 0.36666667, 0.36666667, 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "                          0.        , 0.        , 0.        , 0.        , 0.        ])}],\n",
              "    'layout': {'margin': {'b': 0, 'l': 0, 'r': 0, 't': 30},\n",
              "               'shapes': [{'line': {'dash': 'dash'}, 'type': 'line', 'x0': 0, 'x1': 1, 'y0': 1, 'y1': 0}],\n",
              "               'template': '...',\n",
              "               'xaxis': {'constrain': 'domain', 'range': [0, 1], 'title': {'text': 'Recall'}},\n",
              "               'yaxis': {'constrain': 'domain',\n",
              "                         'range': [0, 1],\n",
              "                         'scaleanchor': 'x',\n",
              "                         'scaleratio': 1,\n",
              "                         'title': {'text': 'Precision'}}}\n",
              "})"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot = results.plot_pr_curves(classes=[\"person\", \"car\"])\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dpR7eosMW4S"
      },
      "source": [
        "## Sample level analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A--63fNMaWT",
        "outputId": "726f302f-cca6-416c-ed6f-6ab4c4df3d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name:        2025.05.29.19.08.20.907977\n",
            "Media type:  image\n",
            "Num samples: 5000\n",
            "Persistent:  True\n",
            "Tags:        []\n",
            "Sample fields:\n",
            "    id:               fiftyone.core.fields.ObjectIdField\n",
            "    filepath:         fiftyone.core.fields.StringField\n",
            "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    created_at:       fiftyone.core.fields.DateTimeField\n",
            "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
            "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    predictions:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    eval_tp:          fiftyone.core.fields.IntField\n",
            "    eval_fp:          fiftyone.core.fields.IntField\n",
            "    eval_fn:          fiftyone.core.fields.IntField\n"
          ]
        }
      ],
      "source": [
        "# Our dataset's schema now contains `eval_*` fields from a confusion matrix\n",
        "print(dataset_clone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOdEugOHO9xs",
        "outputId": "60ba63b5-7831-4c3e-ad94-247bc05999c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['eval']\n"
          ]
        }
      ],
      "source": [
        "# The dataset keeps track of the evaluations that we have run\n",
        "print(dataset_clone.list_evaluations())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCqkfalVPIZM",
        "outputId": "474f16f2-10a6-4ed7-edfb-5c1fef610a38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"key\": \"eval\",\n",
            "    \"version\": \"1.5.2\",\n",
            "    \"timestamp\": \"2025-05-29T19:11:28.592000\",\n",
            "    \"config\": {\n",
            "        \"cls\": \"fiftyone.utils.eval.coco.COCOEvaluationConfig\",\n",
            "        \"type\": \"detection\",\n",
            "        \"method\": \"coco\",\n",
            "        \"pred_field\": \"predictions\",\n",
            "        \"gt_field\": \"ground_truth\",\n",
            "        \"iou\": 0.5,\n",
            "        \"classwise\": true,\n",
            "        \"custom_metrics\": null,\n",
            "        \"iscrowd\": \"iscrowd\",\n",
            "        \"use_masks\": false,\n",
            "        \"use_boxes\": false,\n",
            "        \"tolerance\": null,\n",
            "        \"compute_mAP\": true,\n",
            "        \"iou_threshs\": [\n",
            "            0.5,\n",
            "            0.55,\n",
            "            0.6,\n",
            "            0.65,\n",
            "            0.7,\n",
            "            0.75,\n",
            "            0.8,\n",
            "            0.85,\n",
            "            0.9,\n",
            "            0.95\n",
            "        ],\n",
            "        \"max_preds\": 100,\n",
            "        \"error_level\": 1\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(dataset_clone.get_evaluation_info(\"eval\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTR8QO2uPR31",
        "outputId": "e67fc1fa-0adb-4eed-d462-a6c46ab654f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset:     2025.05.29.19.08.20.907977\n",
            "Media type:  image\n",
            "Num samples: 100\n",
            "Sample fields:\n",
            "    id:               fiftyone.core.fields.ObjectIdField\n",
            "    filepath:         fiftyone.core.fields.StringField\n",
            "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    created_at:       fiftyone.core.fields.DateTimeField\n",
            "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
            "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    predictions:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    eval_tp:          fiftyone.core.fields.IntField\n",
            "    eval_fp:          fiftyone.core.fields.IntField\n",
            "    eval_fn:          fiftyone.core.fields.IntField\n",
            "View stages:\n",
            "    1. Take(size=100, seed=51)\n",
            "    2. FilterLabels(field='predictions', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)\n"
          ]
        }
      ],
      "source": [
        "# Load the view on which we ran the `eval` evaluation\n",
        "eval_view = dataset_clone.load_evaluation_view(\"eval\")\n",
        "print(eval_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8EzkeZrMdYM",
        "outputId": "19d22bbd-efd2-43a7-cfb4-f23d16763e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Detection: {\n",
            "    'id': '6838b0b4cf5d4afce3898fb1',\n",
            "    'attributes': {},\n",
            "    'tags': [],\n",
            "    'label': 'person',\n",
            "    'bounding_box': [\n",
            "        0.006261056289076805,\n",
            "        0.07051300257444382,\n",
            "        0.43123242259025574,\n",
            "        0.8487465977668762,\n",
            "    ],\n",
            "    'mask': None,\n",
            "    'mask_path': None,\n",
            "    'confidence': 0.9155575037002563,\n",
            "    'index': None,\n",
            "    'eval_iou': 0.9590503341005493,\n",
            "    'eval_id': '6838b09ecf5d4afce389228e',\n",
            "    'eval': 'tp',\n",
            "}>\n"
          ]
        }
      ],
      "source": [
        "# Our detections have helpful evaluation data on them\n",
        "sample = high_conf_view.first()\n",
        "print(sample.predictions.detections[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkoSH1D8MbAF",
        "outputId": "35317773-b596-4954-ddad-dc73bbc4074b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Detection: {\n",
            "    'id': '6838b09acf5d4afce388ec7b',\n",
            "    'attributes': {},\n",
            "    'tags': [],\n",
            "    'label': 'potted plant',\n",
            "    'bounding_box': [\n",
            "        0.37028125,\n",
            "        0.3345305164319249,\n",
            "        0.038593749999999996,\n",
            "        0.16314553990610328,\n",
            "    ],\n",
            "    'mask': None,\n",
            "    'mask_path': None,\n",
            "    'confidence': None,\n",
            "    'index': None,\n",
            "    'supercategory': 'furniture',\n",
            "    'iscrowd': 0,\n",
            "}>\n"
          ]
        }
      ],
      "source": [
        "# View the `iscrowd` attribute on a ground truth object\n",
        "sample = dataset_clone.first()\n",
        "print(sample.ground_truth.detections[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBZmKE4BN7JQ"
      },
      "source": [
        "## Evaluation patches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnQqEcRXPm6W"
      },
      "source": [
        "So, now that we have a sense for the aggregate performance of our model, let's dive into sample-level analysis by creating an [evaluation view](https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-evaluation-patches).\n",
        "\n",
        "Any evaluation that you stored on your dataset can be used to generate an [evaluation view](https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-evaluation-patches) that is a patches view creating a sample for every true positive, false positive, and false negative in your dataset.\n",
        "Through this view, you can quickly filter and sort evaluated detections by their type (TP/FP/FN), evaluated IoU, and if they are matched to a crowd object.\n",
        "\n",
        "These evaluation views can be created through Python or directly in the App as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fx0EvjVPcDX",
        "outputId": "15d94b55-c444-483c-c2af-b6e866cad53d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset:     2025.05.29.19.08.20.907977\n",
            "Media type:  image\n",
            "Num patches: 37606\n",
            "Patch fields:\n",
            "    id:               fiftyone.core.fields.ObjectIdField\n",
            "    sample_id:        fiftyone.core.fields.ObjectIdField\n",
            "    filepath:         fiftyone.core.fields.StringField\n",
            "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    created_at:       fiftyone.core.fields.DateTimeField\n",
            "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
            "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    predictions:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    crowd:            fiftyone.core.fields.BooleanField\n",
            "    type:             fiftyone.core.fields.StringField\n",
            "    iou:              fiftyone.core.fields.FloatField\n",
            "View stages:\n",
            "    1. ToEvaluationPatches(eval_key='eval', config=None)\n"
          ]
        }
      ],
      "source": [
        "eval_patches = dataset_clone.to_evaluation_patches(\"eval\")\n",
        "print(eval_patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "MFFVnezFPrEz",
        "outputId": "90eef9a4-b81d-40d9-cc63-a1191f0c668b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "# let's use this evaluation to find false positives with confidence above > .85\n",
        "session_view = high_conf_view\n",
        "print(session.url )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE9-FIvNQ5Pj"
      },
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/false_positive.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCLke7VaRtAY"
      },
      "source": [
        "## View with best performing cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-PSPhsHnR88M",
        "outputId": "78606404-7791-48fd-ee60-7db67610aa2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "# Show samples with most true positives\n",
        "session.view = high_conf_view.sort_by(\"eval_tp\", reverse=True)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihCEA2KaSHAy"
      },
      "source": [
        "## View with the worst performing cases by false positives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "z_Xp3tstR-NL",
        "outputId": "8d219e9e-1936-4b60-b753-5064c859e828"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "# Show samples with most false positives\n",
        "session.view = high_conf_view.sort_by(\"eval_fp\", reverse=True)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK8mbOBdSQ9d"
      },
      "source": [
        "## View with the best performing cases by false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "h9slf4XWSX6F",
        "outputId": "6220cb49-4737-4c9e-94fe-b35f728746ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "# Show samples with most false negatives\n",
        "session.view = high_conf_view.sort_by(\"eval_fn\", reverse=True)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCMZJcBDSagN"
      },
      "source": [
        "## Filtering by bounding box area"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TTlArhXuSkPm"
      },
      "outputs": [],
      "source": [
        "# Compute metadata so we can reference image height/width in our view\n",
        "dataset.compute_metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "yCEC4s_nSme3",
        "outputId": "d6f29223-0026-4c69-ec08-066f34fbd750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Create an expression that will match objects whose bounding boxes have\n",
        "# area less than 32^2 pixels\n",
        "#\n",
        "# Bounding box format is [top-left-x, top-left-y, width, height]\n",
        "# with relative coordinates in [0, 1], so we multiply by image\n",
        "# dimensions to get pixel area\n",
        "#\n",
        "bbox_area = (\n",
        "    F(\"$metadata.width\") * F(\"bounding_box\")[2] *\n",
        "    F(\"$metadata.height\") * F(\"bounding_box\")[3]\n",
        ")\n",
        "small_boxes = bbox_area < 32 ** 2\n",
        "\n",
        "# Create a view that contains only small (and high confidence) predictions\n",
        "small_boxes_view = high_conf_view.filter_labels(\"predictions\", small_boxes)\n",
        "\n",
        "session.view = small_boxes_view\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZgTtZObSpKj",
        "outputId": "d67e949e-b0cc-4cc8-ea1b-907ab8f4dec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating detections...\n",
            " 100% |█████████████████| 100/100 [98.9ms elapsed, 0s remaining, 1.0K samples/s] \n"
          ]
        }
      ],
      "source": [
        "# Create a view that contains only small GT and predicted boxes\n",
        "small_boxes_eval_view = (\n",
        "    high_conf_view\n",
        "    .filter_labels(\"ground_truth\", small_boxes, only_matches=False)\n",
        "    .filter_labels(\"predictions\", small_boxes, only_matches=False)\n",
        ")\n",
        "\n",
        "# Run evaluation\n",
        "small_boxes_results = small_boxes_eval_view.evaluate_detections(\n",
        "    \"predictions\",\n",
        "    gt_field=\"ground_truth\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZURNr4GS5pQ",
        "outputId": "9c558a4a-d23d-4f52-ebbe-711ed1dff2da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "       person       0.80      0.06      0.10        72\n",
            "          car       0.80      0.19      0.31        21\n",
            "        chair       0.00      0.00      0.00         8\n",
            "         book       0.00      0.00      0.00        22\n",
            "       bottle       0.00      0.00      0.00        13\n",
            "          cup       0.00      0.00      0.00        10\n",
            " dining table       0.00      0.00      0.00         3\n",
            "traffic light       0.00      0.00      0.00        21\n",
            "         bowl       0.00      0.00      0.00         1\n",
            "      handbag       0.00      0.00      0.00         4\n",
            "\n",
            "    micro avg       0.73      0.05      0.09       175\n",
            "    macro avg       0.16      0.02      0.04       175\n",
            " weighted avg       0.43      0.05      0.08       175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the 10 most common small object classes\n",
        "small_counts = small_boxes_eval_view.count_values(\"ground_truth.detections.label\")\n",
        "classes_top10_small = sorted(small_counts, key=counts.get, reverse=True)[:10]\n",
        "\n",
        "# Print a classification report for the top-10 small object classes\n",
        "small_boxes_results.print_report(classes=classes_top10_small)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUodNpp3TLlx"
      },
      "source": [
        "## Inspecting the crowd views"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix1viEAcTAUd",
        "outputId": "12af113e-ea32-457f-eb89-60e31632ce1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Detection: {\n",
            "    'id': '6838b09acf5d4afce388ec7b',\n",
            "    'attributes': {},\n",
            "    'tags': [],\n",
            "    'label': 'potted plant',\n",
            "    'bounding_box': [\n",
            "        0.37028125,\n",
            "        0.3345305164319249,\n",
            "        0.038593749999999996,\n",
            "        0.16314553990610328,\n",
            "    ],\n",
            "    'mask': None,\n",
            "    'mask_path': None,\n",
            "    'confidence': None,\n",
            "    'index': None,\n",
            "    'supercategory': 'furniture',\n",
            "    'iscrowd': 0,\n",
            "}>\n"
          ]
        }
      ],
      "source": [
        "# View the `iscrowd` attribute on a ground truth object\n",
        "sample = dataset_clone.first()\n",
        "print(sample.ground_truth.detections[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "JeX15hDlTEGD",
        "outputId": "939b206e-1736-4761-fbed-06a18ae85a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "# Create a view that contains only samples for which at least one detection has\n",
        "# its iscrowd attribute set to 1\n",
        "crowded_images_view = high_conf_view.match(\n",
        "    F(\"ground_truth.detections\").filter(F(\"iscrowd\") == 1).length() > 0\n",
        ")\n",
        "\n",
        "session.view = crowded_images_view\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1lGHbQwjTP5f",
        "outputId": "84165826-49d1-45fc-dd48-a4d1f870f912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the crowd by the number of false positives\n",
        "session.view = crowded_images_view.sort_by(\"eval_fp\", reverse=True)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdR3T7rgUy2t"
      },
      "source": [
        "## Using the model to improve the dataset (active learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "oYjvUA63Uh7o"
      },
      "outputs": [],
      "source": [
        "# Tag all highly confident false positives as \"possibly-missing\"\n",
        "(\n",
        "    high_conf_view\n",
        "        .filter_labels(\"predictions\", F(\"eval\") == \"fp\")\n",
        "        .select_fields(\"predictions\")\n",
        "        .tag_labels(\"possibly-missing\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKcDI-_DVP0c"
      },
      "source": [
        "These tagged labels could then be sent off to our annotation provider of choice for review and addition to the ground truth labels. FiftyOne currently offers integrations for [Scale AI](https://voxel51.com/docs/fiftyone/api/fiftyone.utils.scale.html), [Labelbox](https://voxel51.com/docs/fiftyone/api/fiftyone.utils.labelbox.html), and [CVAT](https://voxel51.com/docs/fiftyone/api/fiftyone.types.dataset_types.html?highlight=cvat#fiftyone.types.dataset_types.CVATImageDataset).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TddG37ygTwmB",
        "outputId": "8330b800-c927-47be-8279-f2e4b633f918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████████████| 0/0 [11.5ms elapsed, ? remaining, ? samples/s] \n"
          ]
        }
      ],
      "source": [
        "# Export all labels with the `possibly-missing` tag in CVAT format\n",
        "(\n",
        "    dataset\n",
        "        .select_labels(tags=[\"possibly-missing\"])\n",
        "        .export(\"./possibly_missing_labels\", fo.types.CVATImageDataset)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz4z1poBVLzx"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, we covered loading a dataset into FiftyOne and analyzing the performance of an out-of-the-box object detection model on the dataset.\n",
        "\n",
        "**So, what's the takeaway?**\n",
        "\n",
        "Aggregate evaluation results for an object detector are important, but they alone don't tell the whole story of a model's performance. It's critical to study the failure modes of your model so you can take the right actions to improve them.\n",
        "\n",
        "In this tutorial, we covered two types of analysis:\n",
        "\n",
        "- Analyzing the performance of your detector across different strata, like high confidence, small objects in crowded scenes\n",
        "- Inspecting the hardest samples in your dataset to diagnose the underlying issue, whether it be your detector or the ground truth annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRQvXyp-VZxa"
      },
      "source": [
        "## About this tutorial\n",
        "\n",
        "This tutorial is based on [FiftyOne's documentation](https://docs.voxel51.com/tutorials/evaluate_detections.html). You will notice a couple of minor changes.\n",
        "\n",
        "* Views for the app launch on their own window, this makes it easier for us to inspect the output of our views on the app.\n",
        "* We create a clone of the COCO dataset at the start of the notebook so that we can go back to its original state if we want\n",
        "* I replaced Faster R-CNN for RetinaNet. As an exercise I encourage to try it with [Faster R-CNN from our model zoo](https://docs.voxel51.com/model_zoo/models.html#faster-rcnn-resnet50-fpn-coco-torch) or through our [integration with Ultralytics's YOLO](https://docs.voxel51.com/integrations/ultralytics.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3Z1BeHDZAG-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOAIpcAZwc32KLcqY35LQ+0",
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".fiftyone-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
