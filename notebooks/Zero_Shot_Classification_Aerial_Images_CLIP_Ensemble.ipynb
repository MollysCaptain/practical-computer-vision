{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "2554b"
   },
   "source": [
    "# Intro to Dataset Curation with FiftyOne and CLIP (Part 2 of 2)\n",
    "\n",
    "In this notebook we explore the use of:\n",
    "\n",
    "* FiftyOne's dataset curation SDK and visualization app\n",
    "* Multimodal embeddings (text + image) from the [CLIP](https://arxiv.org/pdf/2103.00020) model to produce labels for images (aka Zero-shot classification)\n",
    "\n",
    "We label dataset of aerial images from Google Earth View. This is the output of deduplication that we performed [in the previous notebook](https://github.com/andandandand/practical-computer-vision/blob/main/notebooks/Intro_Dataset_Curation_Deduplicate_Aerial_Images.ipynb).\n",
    "\n",
    "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/clip_ensemble_labels.png?raw=true)\n",
    "\n",
    "In part 2, we use the CLIP model to produce labels for the images, and then visualize the final result in FiftyOne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellUniqueIdByVincent": "11255"
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellUniqueIdByVincent": "d4927"
   },
   "outputs": [],
   "source": [
    "parent_path = Path(\"/Users/antonio/Documents/Projects/GettingStartedWithFiftyOne/local_run/\")\n",
    "aerial_images_path = parent_path / 'data/aerial_images'\n",
    "augmented_aerial_images_path = parent_path / 'data/augmented_aerial_images'\n",
    "# You can also import the full dataset if you ran the notebook on deduplication first (adapt the path accordingly)\n",
    "aerial_images_without_duplicates = parent_path / 'data/aerial_images_without_duplicates/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'aerial-images-tagged' exists. Deleting...\n",
      "Dataset 'aerial-images-tagged' deleted.\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset exists and delete it (dataset names are unique in FiftyOne)\n",
    "dataset_name = \"aerial-images-tagged\"  \n",
    "\n",
    "if dataset_name in fo.list_datasets():\n",
    "    print(f\"Dataset '{dataset_name}' exists. Deleting...\")\n",
    "    fo.delete_dataset(dataset_name)\n",
    "    print(f\"Dataset '{dataset_name}' deleted.\")\n",
    "else:\n",
    "    print(f\"Dataset '{dataset_name}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellUniqueIdByVincent": "cecd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 113/113 [18.5ms elapsed, 0s remaining, 6.1K samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |█████████████████| 113/113 [18.5ms elapsed, 0s remaining, 6.1K samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metadata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.core.metadata:Computing metadata...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 113/113 [56.7ms elapsed, 0s remaining, 2.0K samples/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |█████████████████| 113/113 [56.7ms elapsed, 0s remaining, 2.0K samples/s] \n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=aerial_images_path,\n",
    "    dataset_type=fo.types.ImageDirectory,\n",
    "    name=dataset_name,\n",
    "    persistent=True\n",
    ")\n",
    "\n",
    "dataset.compute_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellUniqueIdByVincent": "a6ae5"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellUniqueIdByVincent": "188a3"
   },
   "outputs": [],
   "source": [
    "text_prompt = 'an aerial photo of'\n",
    "\n",
    "classes = ['a river',\n",
    "           'a river in the jungle',\n",
    "           'a river next to an urban area',\n",
    "           'a river delta merging with the sea',\n",
    "           'a body of water',\n",
    "           'a body of water next to an urban area',\n",
    "           'a jungle',\n",
    "           'a forest',\n",
    "           'a river in a forest',\n",
    "           'a farmland',\n",
    "           'a coast',\n",
    "           'a desert',\n",
    "           \"a harbor next to a desert\",\n",
    "           'a desert next to a river',\n",
    "           'a desert next to a body of water',\n",
    "           'a desert next to an urban area',\n",
    "           'a desert next to a coast',\n",
    "           'a desert next to a forest',\n",
    "           'terrain covered by snow',\n",
    "           'a city',\n",
    "           'an airport',\n",
    "           'a sports stadium',\n",
    "           'an urban area',\n",
    "           'a city next to the coast',\n",
    "           'military planes parked next to each other',\n",
    "           'containers in a harbor',\n",
    "           'ships in the ocean',\n",
    "           'the ocean',\n",
    "           'a beach',\n",
    "           'a beach next to an urban area',\n",
    "           'a mountainscape',\n",
    "           'a refinery',\n",
    "           'ships and containers in a harbor',\n",
    "           'ships and boats in a harbor, next to an urban area',\n",
    "           'dense vegetation next to a desert',\n",
    "           'an island',\n",
    "           'a harbor next to an urban area',\n",
    "           'antartica or artic area, ice and water',\n",
    "           'railroad tracks',\n",
    "           'a train station', \n",
    "           'a highway', \n",
    "           'farming terraces',\n",
    "           'an oil rig in the sea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellUniqueIdByVincent": "c45fa"
   },
   "outputs": [],
   "source": [
    "clip_model = foz.load_zoo_model(\n",
    "    \"clip-vit-base32-torch\",\n",
    "    text_prompt=text_prompt,\n",
    "    classes=classes,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is loaded on cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"The model is loaded on {clip_model._device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellUniqueIdByVincent": "81917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 113/113 [2.5s elapsed, 0s remaining, 44.8 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |█████████████████| 113/113 [2.5s elapsed, 0s remaining, 44.8 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "dataset.apply_model(\n",
    "    model=clip_model,\n",
    "    label_field=\"clip_zero_shot_classification\",\n",
    "    # This is how many samples we will show to the model at once\n",
    "    batch_size=32,\n",
    "    store_logits=True,\n",
    "    progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cellUniqueIdByVincent": "ce1f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.core.session.session:Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:5151/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(dataset, auto=False)\n",
    "print(session.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "d68ff"
   },
   "source": [
    "## CLIP-variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_clip_args = {\n",
    "    \"clipa\": {\n",
    "        \"clip_model\": 'hf-hub:UCSC-VLAA/ViT-L-14-CLIPA-datacomp1B',\n",
    "        \"pretrained\": '',\n",
    "        },\n",
    "    \"dfn\": {\n",
    "        \"clip_model\": 'ViT-B-16-quickgelu',\n",
    "        \"pretrained\": 'dfn2b',\n",
    "        },\n",
    "    \"eva02_clip\": {\n",
    "        \"clip_model\": 'EVA02-B-16',\n",
    "        \"pretrained\": 'merged2b_s8b_b131k',\n",
    "        },\n",
    "    \"metaclip\": {\n",
    "        \"clip_model\": 'ViT-B-32-quickgelu',\n",
    "        \"pretrained\": 'metaclip_400m',\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying clipa model\n",
      " 100% |█████████████████| 113/113 [25.7s elapsed, 0s remaining, 4.4 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |█████████████████| 113/113 [25.7s elapsed, 0s remaining, 4.4 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying dfn model\n",
      " 100% |█████████████████| 113/113 [9.3s elapsed, 0s remaining, 13.5 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |█████████████████| 113/113 [9.3s elapsed, 0s remaining, 13.5 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying eva02_clip model\n",
      " 100% |█████████████████| 113/113 [8.3s elapsed, 0s remaining, 14.3 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |█████████████████| 113/113 [8.3s elapsed, 0s remaining, 14.3 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying metaclip model\n",
      " 100% |█████████████████| 113/113 [4.8s elapsed, 0s remaining, 26.7 samples/s]       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |█████████████████| 113/113 [4.8s elapsed, 0s remaining, 26.7 samples/s]       \n"
     ]
    }
   ],
   "source": [
    "for name, args in open_clip_args.items():\n",
    "    print(f\"Applying {name} model\")\n",
    "    clip_model = args[\"clip_model\"]\n",
    "    pretrained = args[\"pretrained\"]\n",
    "    model = foz.load_zoo_model(\n",
    "        \"open-clip-torch\",\n",
    "        clip_model=clip_model,\n",
    "        pretrained=pretrained,\n",
    "        classes=classes,\n",
    "        store_logits=True,\n",
    "        batch_size=32,\n",
    "        text_promopt=text_prompt\n",
    "    )\n",
    "\n",
    "    dataset.apply_model(model, label_field=name, save_logits=True)\n",
    "    session.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:5151/\n"
     ]
    }
   ],
   "source": [
    "session.view = dataset.view()\n",
    "print(session.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', <fiftyone.core.fields.ObjectIdField at 0x347d1a490>),\n",
       "             ('filepath', <fiftyone.core.fields.StringField at 0x3478733d0>),\n",
       "             ('tags', <fiftyone.core.fields.ListField at 0x347883010>),\n",
       "             ('metadata',\n",
       "              <fiftyone.core.fields.EmbeddedDocumentField at 0x34788fe10>),\n",
       "             ('created_at',\n",
       "              <fiftyone.core.fields.DateTimeField at 0x34fe77210>),\n",
       "             ('last_modified_at',\n",
       "              <fiftyone.core.fields.DateTimeField at 0x34788b050>),\n",
       "             ('clip_zero_shot_classification',\n",
       "              <fiftyone.core.fields.EmbeddedDocumentField at 0x3b3a81350>),\n",
       "             ('clipa',\n",
       "              <fiftyone.core.fields.EmbeddedDocumentField at 0x34786bb90>),\n",
       "             ('dfn',\n",
       "              <fiftyone.core.fields.EmbeddedDocumentField at 0x34788d650>),\n",
       "             ('eva02_clip',\n",
       "              <fiftyone.core.fields.EmbeddedDocumentField at 0x347880dd0>),\n",
       "             ('metaclip',\n",
       "              <fiftyone.core.fields.EmbeddedDocumentField at 0x34788da90>)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_field_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sample: {\n",
       "    'id': '6851d07672d2dbe25ef35c3c',\n",
       "    'media_type': 'image',\n",
       "    'filepath': '/Users/antonio/Documents/Projects/GettingStartedWithFiftyOne/local_run/data/aerial_images/abu dhabi.jpeg',\n",
       "    'tags': [],\n",
       "    'metadata': <ImageMetadata: {\n",
       "        'size_bytes': 444325,\n",
       "        'mime_type': 'image/jpeg',\n",
       "        'width': 1800,\n",
       "        'height': 1200,\n",
       "        'num_channels': 3,\n",
       "    }>,\n",
       "    'created_at': datetime.datetime(2025, 6, 17, 20, 30, 46, 530000),\n",
       "    'last_modified_at': datetime.datetime(2025, 6, 17, 20, 31, 45, 399000),\n",
       "    'clip_zero_shot_classification': <Classification: {\n",
       "        'id': '6851d07972d2dbe25ef35cad',\n",
       "        'tags': [],\n",
       "        'label': 'a river delta merging with the sea',\n",
       "        'confidence': 0.24778258800506592,\n",
       "        'logits': array([29.820421, 27.642035, 28.140705, 31.505201, 28.19588 , 27.019852,\n",
       "               26.132374, 26.099657, 27.278822, 26.562037, 28.177319, 29.433647,\n",
       "               30.927937, 31.405432, 30.858131, 28.631344, 30.293571, 28.283974,\n",
       "               26.577253, 24.598516, 24.596449, 22.925438, 25.73516 , 25.968445,\n",
       "               23.026672, 26.247686, 25.34392 , 26.077438, 26.991781, 26.32253 ,\n",
       "               26.861992, 25.888298, 24.51128 , 23.966648, 28.37166 , 27.447449,\n",
       "               26.204636, 26.367895, 26.74857 , 23.609158, 27.700785, 26.026018,\n",
       "               25.765606], dtype=float32),\n",
       "    }>,\n",
       "    'clipa': <Classification: {\n",
       "        'id': '6851d08072d2dbe25ef35d20',\n",
       "        'tags': [],\n",
       "        'label': 'a river delta merging with the sea',\n",
       "        'confidence': 0.9901678562164307,\n",
       "        'logits': None,\n",
       "    }>,\n",
       "    'dfn': <Classification: {\n",
       "        'id': '6851d09b72d2dbe25ef35d92',\n",
       "        'tags': [],\n",
       "        'label': 'a river delta merging with the sea',\n",
       "        'confidence': 0.9969085454940796,\n",
       "        'logits': None,\n",
       "    }>,\n",
       "    'eva02_clip': <Classification: {\n",
       "        'id': '6851d0a772d2dbe25ef35e04',\n",
       "        'tags': [],\n",
       "        'label': 'a river delta merging with the sea',\n",
       "        'confidence': 0.8453239798545837,\n",
       "        'logits': None,\n",
       "    }>,\n",
       "    'metaclip': <Classification: {\n",
       "        'id': '6851d0b172d2dbe25ef35e76',\n",
       "        'tags': [],\n",
       "        'label': 'a river delta merging with the sea',\n",
       "        'confidence': 0.8922300338745117,\n",
       "        'logits': None,\n",
       "    }>,\n",
       "}>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset.first()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_fields = ['clip_zero_shot_classification', 'clipa', 'dfn', 'eva02_clip', 'metaclip']\n",
    "for sample in dataset:\n",
    "    sample_labels = []\n",
    "    confidences = []\n",
    "    for prediction_field in predictions_fields:\n",
    "       sample_labels.append(sample[prediction_field].label)\n",
    "       confidences.append(sample[prediction_field].confidence) \n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    labels_array = np.array(sample_labels)\n",
    "    confidences_array = np.array(confidences)\n",
    "    \n",
    "    # Find unique labels and their counts\n",
    "    unique_labels, counts = np.unique(labels_array, return_counts=True)\n",
    "    \n",
    "    # Find the maximum count and get all labels with that count\n",
    "    max_count = np.max(counts)\n",
    "    most_common_mask = counts == max_count\n",
    "    most_common_labels = unique_labels[most_common_mask]\n",
    "    \n",
    "    most_common_label = most_common_labels[0]\n",
    "    #print(f\"Most common label: {most_common_label}\")\n",
    "    \n",
    "    # Get indices for ONLY the first most common label\n",
    "    indices = np.where(labels_array == most_common_label)[0]\n",
    "    \n",
    "    # Calculate mean confidence for this specific label only\n",
    "    conf_mean = np.mean(confidences_array[indices])\n",
    "\n",
    "    # Save the most common label and its mean confidence as a Classification \n",
    "    sample['most_common_label'] = fo.Classification(label=most_common_label, confidence=conf_mean)\n",
    "    sample.save()\n",
    "    \n",
    "session.refresh()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the dataset with consensus labeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:5151/\n"
     ]
    }
   ],
   "source": [
    "# Launch the FiftyOne app to visualize the dataset\n",
    "session.view = dataset.view()\n",
    "print(session.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.utils.data.exporters:Exporting samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |████████████████████| 113/113 [106.1ms elapsed, 0s remaining, 1.1K docs/s]    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |████████████████████| 113/113 [106.1ms elapsed, 0s remaining, 1.1K docs/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset exported to: /Users/antonio/Documents/Projects/GettingStartedWithFiftyOne/local_run/data/tagged_aerial_images\n"
     ]
    }
   ],
   "source": [
    "# Export to disk\n",
    "export_dir = str(parent_path / \"data/tagged_aerial_images\")\n",
    "dataset.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    "    export_media=True,  # Include media files,\n",
    "    overwrite=True  # Overwrite existing files if they exist\n",
    ")\n",
    "print(f\"Dataset exported to: {export_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.utils.data.importers:Importing samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 113/113 [5.0ms elapsed, 0s remaining, 22.7K samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |█████████████████| 113/113 [5.0ms elapsed, 0s remaining, 22.7K samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Import from disk\n",
    "imported_dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=export_dir,\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing most_common_label field:\n",
      "Sample 1: farming terraces (conf: 0.559)\n",
      "Sample 2: a river delta merging with the sea (conf: 0.765)\n",
      "Sample 3: a farmland (conf: 0.510)\n"
     ]
    }
   ],
   "source": [
    "# Test that your custom field works correctly\n",
    "print(\"Testing most_common_label field:\")\n",
    "for i, sample in enumerate(imported_dataset.take(3)):\n",
    "    if hasattr(sample, 'most_common_label'):\n",
    "        print(f\"Sample {i+1}: {sample.most_common_label.label} (conf: {sample.most_common_label.confidence:.3f})\")\n",
    "    else:\n",
    "        print(f\"Sample {i+1}: No most_common_label field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "vincent": {
   "sessionId": "1a9452eaf56410e78d5466f1_2025-06-16T13-49-07-353Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
