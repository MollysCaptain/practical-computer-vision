{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intro to Dataset Curation with FiftyOne and CLIP (Part 1 of 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook we explore the use of:\n",
        "\n",
        "* FiftyOne's dataset curation SDK and visualization app \n",
        "* Multimodal embeddings (text + image) from the [CLIP](https://arxiv.org/pdf/2103.00020) model \n",
        "* Deduplication of images based on embeddings and cryptographic hashes\n",
        "\n",
        "We do this by curating a dataset of aerial images from Google Earth View. Some of the images are duplicated through near and exact copies, and we will use FiftyOne to identify and remove them.\n",
        "\n",
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/has_exact_duplicate.png?raw=true)\n",
        "\n",
        "In part 2, we use the CLIP model to produce labels for the images, and then visualize the final result in FiftyOne."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellUniqueIdByVincent": "08d75",
        "id": "un2I5sT9HKx4"
      },
      "outputs": [],
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.brain as fob\n",
        "import fiftyone.zoo as foz\n",
        "import fiftyone.core.utils as fou\n",
        "from fiftyone import ViewField as F\n",
        "from pathlib import Path\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import connected_components\n",
        "from typing import List, Tuple, Dict, Set\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define paths for local folders\n",
        "\n",
        "To reproduce, download the files from the [Google Drive folder](https://drive.google.com/drive/folders/1zkrteGx7HMWIpZWTuKArJKoocDa77dQH?usp=drive_link). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellUniqueIdByVincent": "b384b",
        "id": "wgsjy6vr92Jk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "153"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_path = Path(\"/Users/antonio/Documents/Projects/GettingStartedWithFiftyOne/local_run/\")\n",
        "dataset_dir = parent_path / \"data/aerial_images_with_duplicates\"\n",
        "len(os.listdir(dataset_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "ac9e5",
        "id": "ClNBWTTS-mAW"
      },
      "source": [
        "https://docs.voxel51.com/user_guide/dataset_creation/datasets.html#imagedirectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellUniqueIdByVincent": "a4cf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU2unG8g-j1_",
        "outputId": "26a7d6bc-974d-4cbe-d005-dc3470533b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████████| 152/152 [15.8ms elapsed, 0s remaining, 9.6K samples/s]      \n"
          ]
        }
      ],
      "source": [
        "# Create the dataset\n",
        "dataset = fo.Dataset.from_dir(\n",
        "    dataset_dir=dataset_dir,\n",
        "    dataset_type=fo.types.ImageDirectory,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "1de5c",
        "id": "6SUyA7NAAGF3"
      },
      "source": [
        "## Compute metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellUniqueIdByVincent": "0d0c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipf4fjB-IhiM",
        "outputId": "25d18b61-7f1a-41e5-833e-0789f414cfac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing metadata...\n",
            " 100% |█████████████████| 152/152 [51.0ms elapsed, 0s remaining, 3.0K samples/s] \n"
          ]
        }
      ],
      "source": [
        "dataset.compute_metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We can add the num_pixels field to each sample\n",
        "for sample in dataset: \n",
        "    sample[\"metadata.num_pixels\"] = sample.metadata.width * sample.metadata.height\n",
        "    sample.save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/metadata_aggregation.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellUniqueIdByVincent": "344e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "uht1FK4jHP70",
        "outputId": "01e8185a-d1d8-4b0e-843c-b9529bcfd405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Session launched. Run `session.show()` to open the App in a cell output.\n",
            "http://localhost:5151/\n"
          ]
        }
      ],
      "source": [
        "session = fo.launch_app(dataset, auto=False)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "d9fce",
        "id": "Wl55Ct4lBYc2"
      },
      "source": [
        "## Produce similarity index based on CLIP embeddings \n",
        "\n",
        "Embeddings are computed and images have a defined similarity index to others based on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellUniqueIdByVincent": "8e547",
        "id": "w9ViCMw8sL98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing embeddings...\n",
            " 100% |█████████████████| 152/152 [5.0s elapsed, 0s remaining, 30.2 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "# Index images by similarity\n",
        "image_index = fob.compute_similarity(\n",
        "    dataset,\n",
        "    model=\"clip-vit-base32-torch\",\n",
        "    brain_key=\"img_similarity\",\n",
        "    embeddings=\"clip_embeddings\",\n",
        ")\n",
        "\n",
        "# Refresh the FO app session to see the new brain key\n",
        "session.refresh()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This index can be prompter for similar images through text queries\n",
        "image_index.config.supports_prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellUniqueIdByVincent": "1e7c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U4JhpW9Vzoc",
        "outputId": "0d952532-e399-49a5-db1e-53e0e8a4ad5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(152, 512)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Each sample now has a 'clip_embeddings' field\n",
        "np.array(dataset.values('clip_embeddings')).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/a_coast_search.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://localhost:5151/\n"
          ]
        }
      ],
      "source": [
        "session.view = dataset.view()\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellUniqueIdByVincent": "615cd",
        "id": "kgu71P9LBp8E"
      },
      "source": [
        "## Dimensionality reduction and uniqueness computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellUniqueIdByVincent": "55ae8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_pCNwSvSnGH",
        "outputId": "11c19254-686f-45c6-d37f-a61372b078ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating visualization...\n",
            "Computing uniqueness...\n",
            "Uniqueness computation complete\n"
          ]
        }
      ],
      "source": [
        "# Here we project the high-dimensional embeddings to a 2D space using PCA\n",
        "vis_results = fob.compute_visualization(dataset,\n",
        "                                        embeddings='clip_embeddings',\n",
        "                                        method='pca',\n",
        "               # We need the brain_key in order to access the run from the FiftyOne app\n",
        "                                        brain_key='clip_pca')\n",
        "\n",
        "# Here we compute how unique each sample is according to its embeddings (on its full dimensionality, not the 2D PCA projection)\n",
        "fob.compute_uniqueness(dataset, embeddings=\"clip_embeddings\", \n",
        "                       uniqueness_field=\"uniqueness\")\n",
        "\n",
        "session.refresh()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![]()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/embeddings_for_aerial_images.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellUniqueIdByVincent": "9af91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "vdhcps2lTF0L",
        "outputId": "2891c542-0fb9-488d-df61-bc6a6fbbe167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://localhost:5151/\n"
          ]
        }
      ],
      "source": [
        "# Sort the dataset by uniqueness and display it in the FiftyOne app\n",
        "session.view = dataset.view().sort_by(\"uniqueness\", reverse=False)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query images by their similarity neighborhood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/similarity_neighorhood.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellUniqueIdByVincent": "68b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "_RIBCkmAxRGe",
        "outputId": "d1755f67-c1f5-4cd4-9cca-70551d121a7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://localhost:5151/\n"
          ]
        }
      ],
      "source": [
        "a_sample_id = dataset.first().id\n",
        "images_similar_to_query = dataset.sort_by_similarity(a_sample_id, k = 5)\n",
        "session.view = images_similar_to_query\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing near-duplicates with FiftyOne's Brain\n",
        "\n",
        "In most cases, this is all you need. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/near-duplicates-view.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing duplicate samples...\n",
            "Duplicates computation complete\n",
            "http://localhost:5151/\n"
          ]
        }
      ],
      "source": [
        "## Computing near duplicates with FiftyOne's Brain\n",
        "# Calculate near duplicates\n",
        "# https://docs.voxel51.com/brain.html#near-duplicates\n",
        "dup_index = fob.compute_near_duplicates(\n",
        "    dataset,\n",
        "    embeddings=\"clip_embeddings\",\n",
        "    # may need to change this distance measure for non-default mode: thresh=0.02,\n",
        "    )\n",
        "\n",
        "duplicates_view = dup_index.duplicates_view(\n",
        "    type_field=\"dup_type\",\n",
        "    id_field=\"dup_id\",\n",
        "    dist_field=\"dup_dist\",\n",
        ")\n",
        "\n",
        "session.view = duplicates_view\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom logic using embeddings to deduplicate the dataset \n",
        "\n",
        "In the next sections, we define custom logic to deduplicate the dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(152, 512)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings = np.array(dataset.values(\"clip_embeddings\"))\n",
        "embeddings.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(152, 152)\n",
            "[[1.         0.65603428 0.76139458 ... 0.78982186 0.60588079 0.74822055]\n",
            " [0.65603428 1.         0.61192745 ... 0.70855715 0.71941159 0.64096841]\n",
            " [0.76139458 0.61192745 1.         ... 0.71788463 0.60342808 0.70858424]\n",
            " ...\n",
            " [0.78982186 0.70855715 0.71788463 ... 1.         0.62677964 0.65616631]\n",
            " [0.60588079 0.71941159 0.60342808 ... 0.62677964 1.         0.60055011]\n",
            " [0.74822055 0.64096841 0.70858424 ... 0.65616631 0.60055011 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "# Here we compute the cosine similarity matrix for the embeddings\n",
        "# This matrix will show how similar each image is to every other image\n",
        "similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "print(similarity_matrix.shape)\n",
        "print(similarity_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 6.66133815e-16,  6.56034282e-01,  7.61394581e-01, ...,\n",
              "         7.89821865e-01,  6.05880788e-01,  7.48220547e-01],\n",
              "       [ 6.56034282e-01,  2.22044605e-16,  6.11927450e-01, ...,\n",
              "         7.08557149e-01,  7.19411594e-01,  6.40968407e-01],\n",
              "       [ 7.61394581e-01,  6.11927450e-01, -6.66133815e-16, ...,\n",
              "         7.17884629e-01,  6.03428082e-01,  7.08584244e-01],\n",
              "       ...,\n",
              "       [ 7.89821865e-01,  7.08557149e-01,  7.17884629e-01, ...,\n",
              "        -6.66133815e-16,  6.26779638e-01,  6.56166311e-01],\n",
              "       [ 6.05880788e-01,  7.19411594e-01,  6.03428082e-01, ...,\n",
              "         6.26779638e-01,  1.11022302e-15,  6.00550106e-01],\n",
              "       [ 7.48220547e-01,  6.40968407e-01,  7.08584244e-01, ...,\n",
              "         6.56166311e-01,  6.00550106e-01,  4.44089210e-16]],\n",
              "      shape=(152, 152))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n = len(similarity_matrix)\n",
        "# We subtract the identity matrix to avoid self-similarity\n",
        "# (i.e., each image is perfectly similar to itself)\n",
        "similarity_matrix = similarity_matrix - np.identity(n)\n",
        "similarity_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(np.float64(0.700507304406335), np.float64(0.10059558272340646))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(similarity_matrix), np.std(similarity_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(np.float64(-1.887379141862766e-15), np.float64(1.0000000000000009))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.min(similarity_matrix), np.max(similarity_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add computation of max similarity in every sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max similarities shape: (152,)\n",
            "Max similarity values: [0.96460098 0.92687716 0.92203622 0.97286515 0.95821717 0.9413509\n",
            " 0.96616375 0.88028087 0.93127503 0.91830668]\n"
          ]
        }
      ],
      "source": [
        "# Create a copy of similarity matrix and set diagonal to -1 (or very low value)\n",
        "similarity_no_self = similarity_matrix.copy()\n",
        "np.fill_diagonal(similarity_no_self, -1)  # Mask self-similarities\n",
        "\n",
        "# Get max similarity for each image\n",
        "max_similarities = np.max(similarity_no_self, axis=1)\n",
        "\n",
        "print(f\"Max similarities shape: {max_similarities.shape}\")\n",
        "print(f\"Max similarity values: {max_similarities[:10]}\")  # First 10 values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added max_similarity and most_similar_image_id fields to dataset\n"
          ]
        }
      ],
      "source": [
        "# Add max similarity as a field to each sample\n",
        "id_map = [s.id for s in dataset.select_fields([\"id\"])]\n",
        "\n",
        "# Get both max value and index of most similar image\n",
        "similarity_no_self = similarity_matrix.copy()\n",
        "np.fill_diagonal(similarity_no_self, -1)\n",
        "\n",
        "max_similarities = np.max(similarity_no_self, axis=1)\n",
        "most_similar_indices = np.argmax(similarity_no_self, axis=1)\n",
        "\n",
        "for idx, sample in enumerate(dataset):\n",
        "    sample[\"max_similarity\"] = float(max_similarities[idx])\n",
        "    sample[\"most_similar_image_id\"] = id_map[most_similar_indices[idx]]\n",
        "    sample.save()\n",
        "\n",
        "print(\"Added max_similarity and most_similar_image_id fields to dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/Most_similar_images.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://localhost:5151/\n"
          ]
        }
      ],
      "source": [
        "session.refresh()\n",
        "session.view = dataset.view().sort_by(\"max_similarity\", reverse=True)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tagging samples for removal based on similarity threshold and image size \n",
        "\n",
        "Here we define custom logic to keep the image with bigger size out of the similarity neighborhood.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageDeduplicator:\n",
        "    \"\"\"\n",
        "    Expert image deduplication system using cosine similarity neighborhoods.\n",
        "    \n",
        "    The algorithm works by:\n",
        "    1. Converting similarity matrix to adjacency graph\n",
        "    2. Finding connected components (neighborhoods)  \n",
        "    3. Selecting highest resolution image from each neighborhood\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, similarity_matrix: np.ndarray, image_dimensions, \n",
        "                 similarity_threshold: float = 0.8):\n",
        "        \"\"\"\n",
        "        Initialize the deduplicator.\n",
        "        \n",
        "        Args:\n",
        "            similarity_matrix: Square cosine similarity matrix from sklearn\n",
        "            image_dimensions: List of (height, width) tuples OR list of pixel counts\n",
        "            similarity_threshold: Minimum similarity to consider images duplicates\n",
        "        \"\"\"\n",
        "        self.similarity_matrix = similarity_matrix\n",
        "        self.threshold = similarity_threshold\n",
        "        self.n_images = len(image_dimensions)\n",
        "        \n",
        "        # Handle both tuple format (height, width) and integer format (pixel count)\n",
        "        if isinstance(image_dimensions[0], (tuple, list)):\n",
        "            # Format: [(height, width), ...]\n",
        "            self.image_areas = np.array([h * w for h, w in image_dimensions])\n",
        "        else:\n",
        "            # Format: [pixel_count, ...] (already calculated areas)\n",
        "            self.image_areas = np.array(image_dimensions)\n",
        "        \n",
        "        # Validate inputs\n",
        "        self._validate_inputs()\n",
        "        \n",
        "    def _validate_inputs(self):\n",
        "        \"\"\"Ensure inputs are consistent and valid.\"\"\"\n",
        "        if self.similarity_matrix.shape[0] != self.similarity_matrix.shape[1]:\n",
        "            raise ValueError(\"Similarity matrix must be square\")\n",
        "        \n",
        "        if self.similarity_matrix.shape[0] != len(self.image_areas):\n",
        "            raise ValueError(\"Number of images must match similarity matrix dimensions\")\n",
        "        \n",
        "        if not 0 <= self.threshold <= 1:\n",
        "            raise ValueError(\"Similarity threshold must be between 0 and 1\")\n",
        "    \n",
        "    def _create_adjacency_matrix(self) -> csr_matrix:\n",
        "        \"\"\"\n",
        "        Convert similarity matrix to binary adjacency matrix.\n",
        "        \n",
        "        This is like creating a friendship network - if two images are similar\n",
        "        enough (above threshold), they're \"connected\" in the graph.\n",
        "        \"\"\"\n",
        "        # Create binary adjacency matrix (1 where similarity > threshold)\n",
        "        adjacency = (self.similarity_matrix >= self.threshold).astype(int)\n",
        "        \n",
        "        # Remove self-connections (diagonal should be 0)\n",
        "        np.fill_diagonal(adjacency, 0)\n",
        "        \n",
        "        # Convert to sparse matrix for efficiency with large datasets\n",
        "        return csr_matrix(adjacency)\n",
        "    \n",
        "    def _find_duplicate_neighborhoods(self) -> Tuple[int, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Find connected components in the similarity graph.\n",
        "        \n",
        "        Each connected component represents a \"neighborhood\" of similar images.\n",
        "        Uses Union-Find algorithm under the hood via scipy.\n",
        "        \n",
        "        Returns:\n",
        "            n_components: Number of unique neighborhoods\n",
        "            labels: Array where labels[i] is the neighborhood ID for image i\n",
        "        \"\"\"\n",
        "        adjacency = self._create_adjacency_matrix()\n",
        "        return connected_components(adjacency, directed=False)\n",
        "    \n",
        "    def _select_best_from_neighborhood(self, neighborhood_indices: List[int]) -> int:\n",
        "        \"\"\"\n",
        "        Select the highest resolution image from a neighborhood.\n",
        "        \n",
        "        Args:\n",
        "            neighborhood_indices: List of image indices in this neighborhood\n",
        "            \n",
        "        Returns:\n",
        "            Index of the image with maximum area (height × width)\n",
        "        \"\"\"\n",
        "        neighborhood_areas = self.image_areas[neighborhood_indices]\n",
        "        \n",
        "        # Find index with maximum area within this neighborhood\n",
        "        best_local_idx = np.argmax(neighborhood_areas)\n",
        "        return neighborhood_indices[best_local_idx]\n",
        "    \n",
        "    def deduplicate(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Perform complete deduplication process.\n",
        "        \n",
        "        Returns:\n",
        "            Dictionary containing:\n",
        "            - 'keep_indices': List of image indices to keep\n",
        "            - 'remove_indices': List of image indices to remove  \n",
        "            - 'neighborhoods': Details about each duplicate neighborhood\n",
        "            - 'stats': Summary statistics\n",
        "        \"\"\"\n",
        "        # Find duplicate neighborhoods\n",
        "        n_components, labels = self._find_duplicate_neighborhoods()\n",
        "        \n",
        "        # Group images by neighborhood\n",
        "        neighborhoods = {}\n",
        "        for img_idx in range(self.n_images):\n",
        "            neighborhood_id = labels[img_idx]\n",
        "            if neighborhood_id not in neighborhoods:\n",
        "                neighborhoods[neighborhood_id] = []\n",
        "            neighborhoods[neighborhood_id].append(img_idx)\n",
        "        \n",
        "        # Process each neighborhood\n",
        "        keep_indices = []\n",
        "        remove_indices = []\n",
        "        neighborhood_details = []\n",
        "        \n",
        "        for neighborhood_id, img_indices in neighborhoods.items():\n",
        "            neighborhood_size = len(img_indices)\n",
        "            \n",
        "            if neighborhood_size == 1:\n",
        "                # Single image - definitely keep\n",
        "                keep_indices.extend(img_indices) \n",
        "                neighborhood_details.append({\n",
        "                    'neighborhood_id': neighborhood_id,\n",
        "                    'size': neighborhood_size,\n",
        "                    'images': img_indices,\n",
        "                    'kept': img_indices[0],\n",
        "                    'removed': [],\n",
        "                    'is_duplicate_group': False\n",
        "                })\n",
        "            else:\n",
        "                # Multiple images - select best one\n",
        "                best_idx = self._select_best_from_neighborhood(img_indices)\n",
        "                removed_indices = [idx for idx in img_indices if idx != best_idx]\n",
        "                \n",
        "                keep_indices.append(best_idx)\n",
        "                remove_indices.extend(removed_indices)\n",
        "                \n",
        "                neighborhood_details.append({\n",
        "                    'neighborhood_id': neighborhood_id,\n",
        "                    'size': neighborhood_size,\n",
        "                    'images': img_indices,\n",
        "                    'kept': best_idx,\n",
        "                    'removed': removed_indices,\n",
        "                    'is_duplicate_group': True,\n",
        "                    'kept_area': self.image_areas[best_idx]\n",
        "                })\n",
        "        \n",
        "        # Compile results\n",
        "        results = {\n",
        "            'keep_indices': sorted(keep_indices),\n",
        "            'remove_indices': sorted(remove_indices),\n",
        "            'neighborhoods': neighborhood_details,\n",
        "            'stats': {\n",
        "                'total_images': self.n_images,\n",
        "                'images_to_keep': len(keep_indices),\n",
        "                'images_to_remove': len(remove_indices),\n",
        "                'duplicate_neighborhoods': sum(1 for n in neighborhood_details if n['is_duplicate_group']),\n",
        "                'reduction_percentage': (len(remove_indices) / self.n_images) * 100\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def get_similarity_report(self, results: Dict) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Generate a detailed report of duplicate neighborhoods.\n",
        "        \n",
        "        Args:\n",
        "            results: Output from deduplicate() method\n",
        "            \n",
        "        Returns:\n",
        "            DataFrame with neighborhood analysis\n",
        "        \"\"\"\n",
        "        report_data = []\n",
        "        \n",
        "        for neighborhood in results['neighborhoods']:\n",
        "            if neighborhood['is_duplicate_group']:\n",
        "                # Calculate similarity statistics within this neighborhood\n",
        "                img_indices = neighborhood['images']\n",
        "                neighborhood_similarities = []\n",
        "                \n",
        "                for i, idx1 in enumerate(img_indices):\n",
        "                    for idx2 in img_indices[i+1:]:\n",
        "                        sim = self.similarity_matrix[idx1, idx2]\n",
        "                        neighborhood_similarities.append(sim)\n",
        "                \n",
        "                report_data.append({\n",
        "                    'neighborhood_id': neighborhood['neighborhood_id'],\n",
        "                    'group_size': neighborhood['size'],\n",
        "                    'kept_image': neighborhood['kept'],\n",
        "                    'kept_area': neighborhood['kept_area'],\n",
        "                    'removed_images': neighborhood['removed'],\n",
        "                    'avg_similarity': np.mean(neighborhood_similarities),\n",
        "                    'min_similarity': np.min(neighborhood_similarities),\n",
        "                    'max_similarity': np.max(neighborhood_similarities)\n",
        "                })\n",
        "        \n",
        "        return pd.DataFrame(report_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(75, 77)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Image dimensions for each image\n",
        "dimensions = dataset.values(\"metadata.num_pixels\")\n",
        "\n",
        "# Create deduplicator\n",
        "deduplicator = ImageDeduplicator(\n",
        "    similarity_matrix=similarity_matrix,\n",
        "    image_dimensions=dimensions,\n",
        "    similarity_threshold=0.89\n",
        ")\n",
        "\n",
        "# Run deduplication\n",
        "results = deduplicator.deduplicate()\n",
        "keep_these_images = results['keep_indices']\n",
        "len(keep_these_images), len(results['remove_indices'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://localhost:5151/\n"
          ]
        }
      ],
      "source": [
        "# Convert indices to sample IDs\n",
        "id_map = list(dataset.values(\"id\"))\n",
        "keep_sample_ids = [id_map[idx] for idx in results['keep_indices']]\n",
        "remove_sample_ids = [ id_map[idx] for idx in results['remove_indices'] ]\n",
        "\n",
        "#\n",
        "# Tag samples based on  deduplication results\n",
        "for sample_id in keep_sample_ids:\n",
        "    sample = dataset[sample_id]\n",
        "    if \"keep\" not in sample.tags:\n",
        "        sample.tags.append(\"keep\")\n",
        "        sample.save()\n",
        "\n",
        "for sample_id in remove_sample_ids:\n",
        "    sample = dataset[sample_id]\n",
        "    if \"remove\" not in sample.tags:\n",
        "        sample.tags.append(\"remove\")\n",
        "        sample.save()\n",
        "\n",
        "\n",
        "session.view = dataset.view()\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/keep_or_remove.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset to export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_to_export = dataset.select(keep_sample_ids).clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exporting samples...\n",
            " 100% |████████████████████| 152/152 [206.7ms elapsed, 0s remaining, 735.3 docs/s]     \n",
            "Dataset exported to: /Users/antonio/Documents/Projects/GettingStartedWithFiftyOne/local_run/data/aerial_images_without_duplicates\n"
          ]
        }
      ],
      "source": [
        "# Export the filtered dataset\n",
        "export_dir = str(parent_path / \"data/aerial_images_without_duplicates\")\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "dataset.export(\n",
        "    export_dir=export_dir,\n",
        "    dataset_type=fo.types.FiftyOneDataset,\n",
        "    export_media=True,  # Include media files,\n",
        "    overwrite=True  # Overwrite existing files if they exist\n",
        ")\n",
        "print(f\"Dataset exported to: {export_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Identifying exact duplicates with cryptographic hashes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name:        2025.06.18.03.33.55.222308\n",
            "Media type:  image\n",
            "Num samples: 152\n",
            "Persistent:  False\n",
            "Tags:        []\n",
            "Sample fields:\n",
            "    id:                    fiftyone.core.fields.ObjectIdField\n",
            "    filepath:              fiftyone.core.fields.StringField\n",
            "    tags:                  fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:              fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    created_at:            fiftyone.core.fields.DateTimeField\n",
            "    last_modified_at:      fiftyone.core.fields.DateTimeField\n",
            "    clip_embeddings:       fiftyone.core.fields.VectorField\n",
            "    uniqueness:            fiftyone.core.fields.FloatField\n",
            "    max_similarity:        fiftyone.core.fields.FloatField\n",
            "    most_similar_image_id: fiftyone.core.fields.StringField\n",
            "    dup_type:              fiftyone.core.fields.StringField\n",
            "    dup_id:                fiftyone.core.fields.StringField\n",
            "    dup_dist:              fiftyone.core.fields.FloatField\n",
            "    file_hash:             fiftyone.core.fields.IntField\n"
          ]
        }
      ],
      "source": [
        "for sample in dataset:\n",
        "    sample[\"file_hash\"] = fou.compute_filehash(sample.filepath)\n",
        "    sample.save()\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1443910356823855618"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The cryptographic hash of the first sample's file\n",
        "dataset.first().file_hash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all file hashes from the dataset\n",
        "all_hashes = dataset.values(\"file_hash\")\n",
        "unique_hashes = set(all_hashes)\n",
        "\n",
        "# Number of exact duplicates\n",
        "len(all_hashes) - len(unique_hashes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicated hashes: {-4234900463726162786: 2, -1787873817966792036: 2, 7612953259064190265: 2, 4350666197253316396: 2, -5184153168817535596: 2, 6591950879635974224: 2, -6052362864301787295: 2, -3030682317776363846: 2, -320365807361422914: 2}\n"
          ]
        }
      ],
      "source": [
        "hash_counts = Counter(all_hashes)\n",
        "duplicated_hashes = {hash_val:count for hash_val, count in hash_counts.items() if count > 1}\n",
        "print(f\"Duplicated hashes: {duplicated_hashes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/has_exact_duplicate.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tag all samples with duplicated file hashes\n",
        "samples_with_duplicates = dataset.match(F(\"file_hash\").is_in(duplicated_hashes))\n",
        "samples_with_duplicates.tag_samples(\"has_exact_duplicate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://localhost:5151/\n"
          ]
        }
      ],
      "source": [
        "session.view = dataset.view().sort_by(\"file_hash\")\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the deduplication plug-in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading voxel51/fiftyone-plugins...\n",
            " 100% |████|  329.3Mb/329.3Mb [1.2s elapsed, 0s remaining, 303.6Mb/s]         \n",
            "Skipping existing plugin '@voxel51/brain'\n"
          ]
        }
      ],
      "source": [
        "!fiftyone plugins download \\\n",
        "    https://github.com/voxel51/fiftyone-plugins \\\n",
        "    --plugin-names @voxel51/brain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading jacobmarks/image-deduplication-plugin...\n",
            "  102.1Kb [27.4ms elapsed, ? remaining, 3.6Mb/s] \n",
            "Skipping existing plugin '@jacobmarks/image_deduplication'\n"
          ]
        }
      ],
      "source": [
        "!fiftyone plugins download https://github.com/jacobmarks/image-deduplication-plugin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise\n",
        "\n",
        "* Compare the deduplication performance when you compute the embeddings using [Mobilenet](https://docs.voxel51.com/model_zoo/models.html#mobilenet-v2-imagenet-torch) or [Dino-V2](https://docs.voxel51.com/model_zoo/models.html#mobilenet-v2-imagenet-torch). How do the similarity thresholds for optimal deduplication change with these models? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Further reading \n",
        "\n",
        "* [FiftyOne examples - image deduplication](https://github.com/voxel51/fiftyone-examples/blob/master/examples/image_deduplication.ipynb)\n",
        "* [FiftyOne deduplication plugin](https://voxel51.com/blog/eliminate-image-duplicates-with-fiftyone)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "vincent": {
      "sessionId": "ef40c485749f6f43c2ca088b_2025-06-16T11-51-25-036Z"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
